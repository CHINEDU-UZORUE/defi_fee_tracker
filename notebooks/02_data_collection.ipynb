{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc1a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Solana DeFi Tracker - Data Collection\n",
      "Cache directory: ..\\data\n",
      "Collection timestamp: 2025-09-05 12:07:39\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from Levenshtein import ratio\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add parent directory to sys.path for config imports\n",
    "parent_dir = str(Path().resolve().parent)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "from config.settings import API_KEYS, API_ENDPOINTS\n",
    "\n",
    "print(\"üìä Solana DeFi Tracker - Data Collection\")\n",
    "print(f\"Cache directory: {os.path.normpath('../data')}\")\n",
    "print(f\"Collection timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271dab4",
   "metadata": {},
   "source": [
    "#### Verify Cache Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e499b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cache directory exists: ../data/api_responses\n",
      "‚úÖ Cache directory exists: ../data/processed\n",
      "‚úÖ Cache directory exists: ../data/temp\n"
     ]
    }
   ],
   "source": [
    "# Verify cache directories exist, create if missing\n",
    "cache_dirs = ['../data/api_responses', '../data/processed', '../data/temp']\n",
    "for cache_dir in cache_dirs:\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        print(f\"‚úÖ Created cache directory: {cache_dir}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Cache directory exists: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111488c",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8701ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(url, headers=None, params=None, max_retries=3, is_post=False):\n",
    "    \"\"\"Make API request with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if is_post:\n",
    "                response = requests.post(url, headers=headers, json=params, timeout=30)\n",
    "            else:\n",
    "                response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "def save_raw_data(data, filename, description=\"\"):\n",
    "    \"\"\"Save raw API response to api_responses directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/api_responses/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved raw: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_processed_data(data, filename, description=\"\"):\n",
    "    \"\"\"Save processed data to processed directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/processed/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved processed: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_cache(data, filename, description=\"\"):\n",
    "    \"\"\"Save cache data to temp directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/temp/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved cache: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def load_cache(filename):\n",
    "    \"\"\"Load cache data from temp directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/temp/{filename}\")\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            return load(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to load cache {filename}: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def format_currency(amount):\n",
    "    \"\"\"Format currency amount with appropriate units (K, M, B)\"\"\"\n",
    "    if amount is None or amount == 0:\n",
    "        return \"$0\"\n",
    "    \n",
    "    if amount >= 1_000_000_000:\n",
    "        return f\"${amount/1_000_000_000:.2f}B\"\n",
    "    elif amount >= 1_000_000:\n",
    "        return f\"${amount/1_000_000:.2f}M\"\n",
    "    elif amount >= 1_000:\n",
    "        return f\"${amount/1_000:.2f}K\"\n",
    "    else:\n",
    "        return f\"${amount:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d873c0",
   "metadata": {},
   "source": [
    "#### Step 1: Collect DefiLlama Protocol Data (TVL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5415fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol TVL Data...\n",
      "‚úÖ DefiLlama API working! Found 6366 total protocols\n",
      "‚ö†Ô∏è Excluded 42 CEX-related protocols: Binance CEX, OKX, Bitfinex, Bybit, Gate\n",
      "üíæ Saved cache: Excluded CEX protocols log ‚Üí ..\\data\\temp\\excluded_protocols_20250905_120743.joblib\n",
      "üåü Found 252 Solana DeFi protocols:\n",
      "üìä Total Solana DeFi TVL: $77,652,866,558\n",
      "üìà Active protocols (TVL > 0): 220/252\n",
      "\n",
      "Rank  Protocol                  TVL             Category             1d Change \n",
      "=====================================================================================\n",
      "1     Lido                      $38.28B         Liquid Staking       +0.5%     \n",
      "2     Jito Liquid Staking       $3.03B          Liquid Staking       -1.7%     \n",
      "3     Portal                    $2.76B          Bridge               +1.6%     \n",
      "4     Kamino Lend               $2.66B          Lending              +2.3%     \n",
      "5     Sanctum Validator LSTs    $2.42B          Liquid Staking       +0.9%     \n",
      "6     Jupiter Perpetual Exchan  $2.40B          Derivatives          +0.4%     \n",
      "7     Raydium AMM               $2.31B          Dexs                 -2.4%     \n",
      "8     BlackRock BUIDL           $2.26B          RWA                  +0.0%     \n",
      "9     Maple                     $2.19B          Lending              +4.4%     \n",
      "10    Renzo                     $1.47B          Liquid Restaking     +2.0%     \n",
      "11    Ondo Yield Assets         $1.40B          RWA                  -0.2%     \n",
      "12    Gauntlet                  $1.39B          Risk Curators        +0.3%     \n",
      "13    Jupiter Staked SOL        $1.21B          Liquid Staking       -0.3%     \n",
      "14    Marinade Native           $1.03B          Staking Pool         +0.1%     \n",
      "15    Marinade Liquid Staking   $953.83M        Liquid Staking       -1.0%     \n",
      "16    Unit                      $910.19M        Bridge               +1.4%     \n",
      "17    Drift Trade               $901.40M        Derivatives          +1.5%     \n",
      "18    Meteora DLMM              $662.80M        Dexs                 -0.6%     \n",
      "19    Jupiter Lend              $573.21M        Lending              +4.1%     \n",
      "20    GMX V2 Perps              $545.84M        Derivatives          -0.4%     \n",
      "\n",
      "üìã Category Breakdown:\n",
      "Category                  Count    Total TVL      \n",
      "--------------------------------------------------\n",
      "Liquid Staking            27.0     $47.86B        \n",
      "Lending                   22.0     $5.89B         \n",
      "Dexs                      49.0     $4.71B         \n",
      "RWA                       12.0     $4.62B         \n",
      "Derivatives               18.0     $4.02B         \n",
      "Bridge                    11.0     $3.78B         \n",
      "Liquid Restaking          6.0      $1.63B         \n",
      "Risk Curators             1.0      $1.39B         \n",
      "Staking Pool              4.0      $1.20B         \n",
      "Basis Trading             6.0      $1.02B         \n",
      "üíæ Saved raw: Solana DeFi protocols TVL data ‚Üí ..\\data\\api_responses\\solana_defi_tvl_20250905_120743.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_defi_tvl_20250905_120743.joblib\n",
      "\n",
      "‚úÖ Successfully collected TVL data for 252 Solana DeFi protocols\n",
      "üìÅ DataFrame saved to joblib file for further analysis\n",
      "üìä Dataset includes 252 protocols worth $77,652,866,558 in total TVL\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol TVL Data...\")\n",
    "\n",
    "def get_all_solana_tvl_data():\n",
    "    \"\"\"\n",
    "    Collect TVL data for Solana DeFi protocols from DefiLlama, excluding CEX and CEX-related protocols.\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    # DefiLlama API endpoint for all protocols\n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    protocols_url = f\"{base_url}/protocols\"\n",
    "    \n",
    "    # Make the API request\n",
    "    all_protocols = make_request(protocols_url)\n",
    "    \n",
    "    if not all_protocols:\n",
    "        print(\"‚ùå DefiLlama API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ DefiLlama API working! Found {len(all_protocols)} total protocols\")\n",
    "    \n",
    "    # Comprehensive list of CEX names to exclude\n",
    "    cex_list = [\n",
    "        'binance', 'bybit', 'coinbase', 'kraken', 'kucoin', 'okx',\n",
    "        'crypto.com', 'crypto', 'bitfinex', 'huobi', 'htx', 'gate', 'gate.io',\n",
    "        'mexc', 'bitget', 'gemini', 'bitstamp', 'bithumb', 'bitpanda',\n",
    "        'bitmex', 'coinex', 'upbit', 'revolut', 'coindcx', 'bitflyer',\n",
    "        'coincheck', 'bitbank', 'swissborg', 'deribit'\n",
    "    ]\n",
    "    \n",
    "    # Filter for Solana DeFi protocols (excluding CEX and CEX-related)\n",
    "    solana_protocols = []\n",
    "    excluded_protocols = []\n",
    "    \n",
    "    for protocol in all_protocols:\n",
    "        chains = protocol.get('chains', [])\n",
    "        category = protocol.get('category', '').lower()\n",
    "        name = protocol.get('name', '').lower()\n",
    "        \n",
    "        is_solana = (\n",
    "            'Solana' in chains or \n",
    "            'solana' in chains or\n",
    "            any('solana' in str(chain).lower() for chain in chains) or\n",
    "            protocol.get('chain') == 'Solana'\n",
    "        )\n",
    "        \n",
    "        # Exclude CEX and CEX-related protocols\n",
    "        is_cex_related = (\n",
    "            category == 'cex' or\n",
    "            any(cex in name for cex in cex_list)\n",
    "        )\n",
    "        \n",
    "        if is_solana and not is_cex_related:\n",
    "            tvl_value = protocol.get('tvl') or 0\n",
    "            \n",
    "            solana_protocols.append({\n",
    "                'name': protocol.get('name', 'Unknown'),\n",
    "                'slug': protocol.get('slug', ''),\n",
    "                'tvl': tvl_value,\n",
    "                'chains': chains,\n",
    "                'category': protocol.get('category', 'Unknown'),\n",
    "                'change_1h': protocol.get('change_1h'),\n",
    "                'change_1d': protocol.get('change_1d'),\n",
    "                'change_7d': protocol.get('change_7d'),\n",
    "                'mcap': protocol.get('mcap'),\n",
    "                'symbol': protocol.get('symbol', ''),\n",
    "                'url': protocol.get('url', ''),\n",
    "                'description': protocol.get('description', ''),\n",
    "                'gecko_id': protocol.get(\"coingeckoId\"),\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        elif is_solana and is_cex_related:\n",
    "            excluded_protocols.append((protocol.get('name'), category))\n",
    "    \n",
    "    if excluded_protocols:\n",
    "        print(f\"‚ö†Ô∏è Excluded {len(excluded_protocols)} CEX-related protocols: {', '.join([name for name, _ in excluded_protocols[:5]])}\")\n",
    "        # Save excluded protocols log to cache directory\n",
    "        save_cache(excluded_protocols, f'excluded_protocols_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib', \n",
    "                    \"Excluded CEX protocols log\")  \n",
    "    \n",
    "    if not solana_protocols:\n",
    "        print(\"‚ùå No Solana DeFi protocols found\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(solana_protocols)\n",
    "    \n",
    "    # Sort by TVL descending\n",
    "    df = df.sort_values(by=\"tvl\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üåü Found {len(df)} Solana DeFi protocols:\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_tvl = df['tvl'].sum()\n",
    "    active_protocols = (df['tvl'] > 0).sum()\n",
    "    \n",
    "    print(f\"üìä Total Solana DeFi TVL: ${total_tvl:,.0f}\")\n",
    "    print(f\"üìà Active protocols (TVL > 0): {active_protocols}/{len(df)}\")\n",
    "    \n",
    "    # Display top protocols\n",
    "    print(f\"\\n{'Rank':<5} {'Protocol':<25} {'TVL':<15} {'Category':<20} {'1d Change':<10}\")\n",
    "    print(\"=\" * 85)\n",
    "    \n",
    "    for i, row in df.head(20).iterrows():\n",
    "        tvl_formatted = format_currency(row['tvl'])\n",
    "        change_1d = row['change_1d']\n",
    "        change_str = f\"{change_1d:+.1f}%\" if change_1d is not None else \"N/A\"\n",
    "        \n",
    "        print(f\"{i+1:<5} {row['name'][:24]:<25} {tvl_formatted:<15} \"\n",
    "              f\"{row['category'][:19]:<20} {change_str:<10}\")\n",
    "    \n",
    "    # Show category breakdown\n",
    "    category_breakdown = (\n",
    "        df.groupby(\"category\")['tvl']\n",
    "        .agg(['count', 'sum'])\n",
    "        .rename(columns={'count': 'protocols', 'sum': 'total_tvl'})\n",
    "        .sort_values(by=\"total_tvl\", ascending=False)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã Category Breakdown:\")\n",
    "    print(f\"{'Category':<25} {'Count':<8} {'Total TVL':<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for category, row in category_breakdown.head(10).iterrows():\n",
    "        print(f\"{category[:24]:<25} {row['protocols']:<8} {format_currency(row['total_tvl']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_defi_tvl_{timestamp}.joblib'\n",
    "    save_raw_data(df, filename, 'Solana DeFi protocols TVL data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute the collection\n",
    "tvl_df = get_all_solana_tvl_data()\n",
    "\n",
    "if tvl_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected TVL data for {len(tvl_df)} Solana DeFi protocols\")\n",
    "    print(\"üìÅ DataFrame saved to joblib file for further analysis\")\n",
    "    print(f\"üìä Dataset includes {len(tvl_df)} protocols worth ${tvl_df['tvl'].sum():,.0f} in total TVL\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect TVL data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e972c",
   "metadata": {},
   "source": [
    "#### Step 2: Collect DefiLlama Revenue Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a864fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol Revenue Data...\n",
      "üìä Solana Protocol Revenue Tracker\n",
      "==================================================\n",
      "‚úÖ Collected Solana revenue data\n",
      "Total protocols found: 104\n",
      "üíµ Found revenue data for 91 active protocols:\n",
      "\n",
      "Protocol                  24h Revenue     7d Revenue      30d Revenue    \n",
      "===========================================================================\n",
      "pump.fun                  $1.62M          $10.26M         $45.90M        \n",
      "Axiom                     $1.56M          $10.65M         $53.68M        \n",
      "Jupiter Perpetual Exchan  $785.31K        $5.74M          $23.71M        \n",
      "PumpSwap                  $541.92K        $2.16M          $6.39M         \n",
      "Phantom Wallet            $500.40K        $3.48M          $16.79M        \n",
      "Photon                    $159.93K        $1.05M          $5.94M         \n",
      "Solana                    $146.25K        $1.06M          $4.56M         \n",
      "Meteora DAMM V2           $124.96K        $895.45K        $6.17M         \n",
      "Binance Staked SOL        $124.92K        $572.36K        $1.61M         \n",
      "Raydium AMM               $97.50K         $803.08K        $3.58M         \n",
      "üíæ Saved raw: Solana revenue data ‚Üí ..\\data\\api_responses\\solana_revenue_20250905_120746.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_revenue_20250905_120746.joblib\n",
      "\n",
      "‚úÖ Successfully collected revenue data for 104 protocols\n",
      "üìÅ DataFrame saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol Revenue Data...\")\n",
    "\n",
    "def get_solana_revenue_data():\n",
    "    \"\"\"Collect REVENUE data from DefiLlama\"\"\"\n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    revenue_url = f\"{base_url}/overview/fees/solana\"\n",
    "    \n",
    "    #\n",
    "    params = {\n",
    "        'dataType': 'dailyRevenue', \n",
    "        'excludeTotalDataChart': 'true',\n",
    "        'excludeTotalDataChartBreakdown': 'true'\n",
    "    }\n",
    "    \n",
    "    data = make_request(revenue_url, params=params)\n",
    "    \n",
    "    if not data:\n",
    "        print(\"‚ùå Solana Revenue API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Collected Solana revenue data\")\n",
    "    print(f\"Total protocols found: {len(data.get('protocols', []))}\")\n",
    "    \n",
    "    protocols = data.get('protocols', [])\n",
    "    if not protocols:\n",
    "        print(\"No protocol data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort protocols by total24h in descending order\n",
    "    sorted_protocols = sorted(protocols, \n",
    "                            key=lambda x: x.get('total24h', 0) or 0, \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Build DataFrame\n",
    "    revenue_list = []\n",
    "    for protocol in sorted_protocols:\n",
    "        revenue_list.append({\n",
    "            'protocol': protocol.get('name', 'Unknown'),\n",
    "            'revenue_24h': protocol.get('total24h', 0),  \n",
    "            'revenue_7d': protocol.get('total7d', 0),    \n",
    "            'revenue_30d': protocol.get('total30d', 0),  \n",
    "            'revenue_all_time': protocol.get('totalAllTime', 0),\n",
    "            'data_type': 'revenue',  \n",
    "            'chain': 'solana',\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(revenue_list)\n",
    "    \n",
    "    # Display summary\n",
    "    protocols_with_data = (df['revenue_24h'] > 0).sum()\n",
    "    print(f\"üíµ Found revenue data for {protocols_with_data} active protocols:\")\n",
    "    \n",
    "    # Show top 10\n",
    "    top_protocols = df.sort_values(by=\"revenue_24h\", ascending=False).head(10)\n",
    "    print(f\"\\n{'Protocol':<25} {'24h Revenue':<15} {'7d Revenue':<15} {'30d Revenue':<15}\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    for _, row in top_protocols.iterrows():\n",
    "        if row['revenue_24h'] > 0:\n",
    "            print(f\"{row['protocol'][:24]:<25} {format_currency(row['revenue_24h']):<15} \"\n",
    "                  f\"{format_currency(row['revenue_7d']):<15} {format_currency(row['revenue_30d']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_revenue_{timestamp}.joblib'\n",
    "    save_raw_data(df, filename, 'Solana revenue data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"üìä Solana Protocol Revenue Tracker\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "revenue_df = get_solana_revenue_data()\n",
    "\n",
    "if revenue_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected revenue data for {len(revenue_df)} protocols\")\n",
    "    print(\"üìÅ DataFrame saved to joblib file for further analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect revenue data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e459231",
   "metadata": {},
   "source": [
    "#### Step 3: Collect Solana Fees Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bd14fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol Fees Data...\n",
      "üìä Solana Protocol Fees Tracker\n",
      "==================================================\n",
      "‚úÖ Collected Solana fees data\n",
      "Total protocols found: 117\n",
      "üí∞ Found fee data for 104 active protocols:\n",
      "\n",
      "Protocol                  24h Fees        7d Fees         30d Fees       \n",
      "======================================================================\n",
      "Jupiter Perpetual Exchan  $3.14M          $22.95M         $94.84M        \n",
      "PumpSwap                  $2.99M          $12.54M         $37.80M        \n",
      "pump.fun                  $1.62M          $10.26M         $45.90M        \n",
      "Axiom                     $1.56M          $10.65M         $53.68M        \n",
      "Solana                    $1.24M          $9.06M          $42.67M        \n",
      "Jito Liquid Staking       $1.06M          $4.13M          $12.50M        \n",
      "Meteora DLMM              $988.57K        $7.56M          $53.84M        \n",
      "Sanctum Validator LSTs    $905.43K        $3.64M          $12.86M        \n",
      "Binance Staked SOL        $793.21K        $3.26M          $10.59M        \n",
      "Raydium AMM               $650.80K        $5.37M          $24.34M        \n",
      "üíæ Saved raw: Solana fees data ‚Üí ..\\data\\api_responses\\solana_fees_20250905_120748.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_fees_20250905_120748.joblib\n",
      "\n",
      "‚úÖ Successfully collected fees data for 117 protocols\n",
      "Data saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol Fees Data...\")\n",
    "\n",
    "def get_solana_fees_data():\n",
    "    \n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    fees_url = f\"{base_url}/overview/fees/solana\"\n",
    "    \n",
    "  \n",
    "    params = {\n",
    "        'dataType': 'dailyFees',  \n",
    "        'excludeTotalDataChart': 'true',\n",
    "        'excludeTotalDataChartBreakdown': 'true'\n",
    "    }\n",
    "    \n",
    "    data = make_request(fees_url, params=params)\n",
    "    \n",
    "    if not data:\n",
    "        print(\"‚ùå Solana Fees API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Collected Solana fees data\")\n",
    "    print(f\"Total protocols found: {len(data.get('protocols', []))}\")\n",
    "    \n",
    "    protocols = data.get('protocols', [])\n",
    "    \n",
    "    if not protocols:\n",
    "        print(\"No protocol data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort protocols by total24h in descending order\n",
    "    sorted_protocols = sorted(protocols, \n",
    "                            key=lambda x: x.get('total24h', 0) or 0, \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Build list for DataFrame\n",
    "    fees_list = []\n",
    "    for protocol in sorted_protocols:\n",
    "        fees_list.append({\n",
    "            'protocol': protocol.get('name', 'Unknown'),\n",
    "            'fees_24h': protocol.get('total24h', 0),     \n",
    "            'fees_7d': protocol.get('total7d', 0),       \n",
    "            'fees_30d': protocol.get('total30d', 0),     \n",
    "            'fees_all_time': protocol.get('totalAllTime', 0),\n",
    "            'data_type': 'fees',  # Add data type identifier\n",
    "            'chain': 'solana',\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df2 = pd.DataFrame(fees_list)\n",
    "    \n",
    "    # Display summary\n",
    "    protocols_with_data = (df2['fees_24h'] > 0).sum()\n",
    "    print(f\"üí∞ Found fee data for {protocols_with_data} active protocols:\")\n",
    "    \n",
    "    # Show top 10\n",
    "    top_protocols = df2.sort_values(by=\"fees_24h\", ascending=False).head(10)\n",
    "    print(f\"\\n{'Protocol':<25} {'24h Fees':<15} {'7d Fees':<15} {'30d Fees':<15}\")\n",
    "    print(\"=\" * 70)\n",
    "    for _, row in top_protocols.iterrows():\n",
    "        if row['fees_24h'] > 0:\n",
    "            print(f\"{row['protocol'][:24]:<25} {format_currency(row['fees_24h']):<15} \"\n",
    "                  f\"{format_currency(row['fees_7d']):<15} {format_currency(row['fees_30d']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_fees_{timestamp}.joblib'\n",
    "    save_raw_data(df2, filename, 'Solana fees data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df2\n",
    "\n",
    "\n",
    "print(\"üìä Solana Protocol Fees Tracker\")\n",
    "print(\"=\" * 50)\n",
    "    \n",
    "fees_df = get_solana_fees_data()\n",
    "    \n",
    "if fees_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected fees data for {len(fees_df)} protocols\")\n",
    "    print(\"Data saved to joblib file for further analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect fees data\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb8b34",
   "metadata": {},
   "source": [
    "#### Get all Solana tokens list via Jupiter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b403a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Jupiter token list\n",
    "url = \"https://token.jup.ag/all\"\n",
    "resp = requests.get(url)\n",
    "tokens = resp.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(tokens)\n",
    "\n",
    "# Select useful columns\n",
    "jupiter_df = df[[\"address\", \"symbol\", \"name\", \"decimals\", \"logoURI\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897b208",
   "metadata": {},
   "source": [
    "#### Step 4: Collect CoinGecko Price and Supply Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting CoinGecko Price and Supply Data for Solana DeFi Protocols...\n",
      "\n",
      "üîç Collecting CoinGecko Pro Data for Solana Protocols...\n",
      "‚ö†Ô∏è 8 tokens not found in Jupiter list: Adrena Protocol (adx), Balanced Exchange (baln), Amun (amun), Divvy.Bet (dvy), Renec Lend (rel)\n",
      "üíæ Saved cache: Unmatched tokens log ‚Üí ..\\data\\temp\\unmatched_tokens_20250905_120827.joblib\n",
      "üíæ Saved cache: CoinGecko Pro price cache ‚Üí ..\\data\\temp\\coingecko_pro_price_cache.joblib\n",
      "\n",
      "‚úÖ Successfully collected CoinGecko Pro data!\n",
      "üìä Processed: 125 protocols\n",
      "üéØ Successful matches: 84\n",
      "üìà Success rate: 67.2%\n",
      "üíæ Saved raw: Enhanced CoinGecko data for Solana DeFi protocols ‚Üí ..\\data\\api_responses\\solana_coingecko_enhanced_20250905_120831.joblib\n",
      "\n",
      "üìã Sample of collected data:\n",
      "Protocol                  Symbol   Price        Market Cap      TVL            \n",
      "===========================================================================\n",
      "Jupiter Perpetual Exchan  JUP      $0.4947      $1.54B          $2.40B         \n",
      "Jupiter Staked SOL        JUP      $0.4947      $1.54B          $1.21B         \n",
      "Jupiter Lend              JUP      $0.4947      $1.54B          $573.21M       \n",
      "Saros AMM                 SAROS    $0.3601      $945.29M        $3.44M         \n",
      "Saros DLMM                SAROS    $0.3601      $945.29M        $2.05M         \n",
      "Raydium AMM               RAY      $3.3400      $894.53M        $2.31B         \n",
      "Pyth Network              PYTH     $0.1500      $862.93M        $0             \n",
      "Jito Liquid Staking       JTO      $1.8700      $697.57M        $3.03B         \n",
      "Jito Restaking            JTO      $1.8700      $697.57M        $170.35M       \n",
      "Portal                    W        $0.0770      $365.57M        $2.76B         \n",
      "Drift Trade               DRIFT    $0.5434      $196.60M        $901.40M       \n",
      "Drift Staked SOL          DRIFT    $0.5434      $196.60M        $353.91M       \n",
      "Kamino Lend               KMNO     $0.0554      $149.81M        $2.66B         \n",
      "Kamino Liquidity          KMNO     $0.0554      $149.81M        $295.86M       \n",
      "Orca DEX                  ORCA     $2.2500      $134.97M        $407.59M       \n",
      "\n",
      "üìä Portfolio Summary:\n",
      "  ‚Ä¢ Total Market Cap: $11.48B\n",
      "  ‚Ä¢ Total TVL: $60.71B\n",
      "  ‚Ä¢ Tokens with positive 24h change: 24/80\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting CoinGecko Price and Supply Data for Solana DeFi Protocols...\")\n",
    "\n",
    "def collect_coingecko_data_for_solana_protocols():\n",
    "    \"\"\"Simplified price retrieval for Solana protocols using CoinGecko Pro API.\"\"\"\n",
    "    print(\"\\nüîç Collecting CoinGecko Pro Data for Solana Protocols...\")\n",
    "\n",
    "    # Initialize output dictionary and counters\n",
    "    coingecko_data = {}\n",
    "    processed_count = 0\n",
    "    successful_count = 0\n",
    "\n",
    "    # Load or initialize cache\n",
    "    cache_filepath = os.path.normpath('../data/temp/coingecko_pro_price_cache.joblib')\n",
    "    price_cache = load_cache('coingecko_pro_price_cache.joblib') or {}\n",
    "\n",
    "    # CoinGecko Pro API setup\n",
    "    base_url = API_ENDPOINTS['coingecko']['pro_base_url']   \n",
    "    headers = {\"x-cg-pro-api-key\": API_KEYS['coingecko']}\n",
    "    platform_id = \"solana\"\n",
    "\n",
    "    # Match protocols with Jupiter token list for contract addresses\n",
    "    token_map = {}\n",
    "    unmatched_tokens = []\n",
    "    \n",
    "    # Convert DataFrame to records for compatibility\n",
    "    solana_protocols = tvl_df.to_dict('records') if not tvl_df.empty else []\n",
    "    \n",
    "    for row in solana_protocols:\n",
    "        symbol = str(row.get('symbol', '')).lower().strip()\n",
    "        protocol_name = row.get('name', '')\n",
    "        if symbol in ['-', '', 'nan'] or not symbol:  # Skip invalid symbols\n",
    "            continue\n",
    "        \n",
    "        # Find matching token in Jupiter list\n",
    "        jupiter_match = jupiter_df[jupiter_df['symbol'].str.lower() == symbol]\n",
    "        if not jupiter_match.empty:\n",
    "            token_map[protocol_name] = jupiter_match.iloc[0]['address']\n",
    "        else:\n",
    "            unmatched_tokens.append((protocol_name, symbol))\n",
    "        processed_count += 1\n",
    "\n",
    "    if unmatched_tokens:\n",
    "        print(f\"‚ö†Ô∏è {len(unmatched_tokens)} tokens not found in Jupiter list: {', '.join([f'{name} ({sym})' for name, sym in unmatched_tokens[:5]])}\")\n",
    "        save_cache(unmatched_tokens, f'unmatched_tokens_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib', \"Unmatched tokens log\")\n",
    "\n",
    "    # Batch query for prices (Pro API supports multiple addresses)\n",
    "    contract_addresses = list(token_map.values())\n",
    "    if not contract_addresses:\n",
    "        print(\"‚ùå No valid contract addresses found\")\n",
    "        return coingecko_data, processed_count, successful_count\n",
    "\n",
    "    # Split into chunks to respect API limits (e.g., 100 addresses per request)\n",
    "    chunk_size = 100\n",
    "    for i in range(0, len(contract_addresses), chunk_size):\n",
    "        chunk = contract_addresses[i:i + chunk_size]\n",
    "        chunk_str = ','.join(chunk)\n",
    "        \n",
    "        # Check cache first\n",
    "        cache_key = f\"solana_{chunk_str}\"\n",
    "        if cache_key in price_cache:\n",
    "            prices = price_cache[cache_key]\n",
    "        else:\n",
    "            url = f\"{base_url}/simple/token_price/{platform_id}?contract_addresses={chunk_str}&vs_currencies=usd&include_market_cap=true&include_24hr_change=true&include_24hr_vol=true&include_last_updated_at=true\"\n",
    "            prices = make_request(url, headers=headers)\n",
    "            if prices:\n",
    "                price_cache[cache_key] = prices\n",
    "            else:\n",
    "                print(f\"‚ùå Failed to fetch prices for chunk {i//chunk_size + 1}\")\n",
    "                continue\n",
    "            \n",
    "            # Add delay for Pro API rate limiting\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        # Process each protocol in the chunk\n",
    "        for protocol_name, address in [(k, v) for k, v in token_map.items() if v in chunk]:\n",
    "            if address not in prices:\n",
    "                continue\n",
    "            \n",
    "            price_data = prices[address]\n",
    "            \n",
    "            # Find protocol data from tvl_df for additional info\n",
    "            protocol_match = tvl_df[tvl_df['name'] == protocol_name]\n",
    "            if not protocol_match.empty:\n",
    "                protocol_row = protocol_match.iloc[0]\n",
    "                protocol_key = protocol_row.get('slug', protocol_name.lower().replace(' ', '_'))\n",
    "                symbol = protocol_row.get('symbol', '').upper() if protocol_row.get('symbol') else ''\n",
    "                tvl = protocol_row.get('tvl', 0)\n",
    "                category = protocol_row.get('category', '')\n",
    "            else:\n",
    "                protocol_key = protocol_name.lower().replace(' ', '_')\n",
    "                symbol = ''\n",
    "                tvl = 0\n",
    "                category = ''\n",
    "            \n",
    "            # Create simplified data structure with only available fields\n",
    "            coingecko_data[protocol_key] = {\n",
    "                'protocol_name': protocol_name,\n",
    "                'symbol': symbol,\n",
    "                'current_price_usd': price_data.get('usd', 0) or 0,\n",
    "                'market_cap_usd': price_data.get('usd_market_cap', 0) or 0,\n",
    "                'price_change_24h_percent': price_data.get('usd_24h_change', 0) or 0,\n",
    "                'tvl': tvl,\n",
    "                'category': category,\n",
    "                'collection_timestamp': datetime.now()\n",
    "            }\n",
    "            successful_count += 1\n",
    "\n",
    "    # Save cache\n",
    "    save_cache(price_cache, 'coingecko_pro_price_cache.joblib', \"CoinGecko Pro price cache\")\n",
    "\n",
    "    return coingecko_data, processed_count, successful_count\n",
    "\n",
    "# Execute the collection\n",
    "if 'tvl_df' in locals() and not tvl_df.empty and 'jupiter_df' in locals() and not jupiter_df.empty:\n",
    "    coingecko_data, processed_count, successful_count = collect_coingecko_data_for_solana_protocols()\n",
    "    \n",
    "    if coingecko_data:\n",
    "        print(f\"\\n‚úÖ Successfully collected CoinGecko Pro data!\")\n",
    "        print(f\"üìä Processed: {processed_count} protocols\")\n",
    "        print(f\"üéØ Successful matches: {successful_count}\")\n",
    "        print(f\"üìà Success rate: {(successful_count/processed_count*100):.1f}%\")\n",
    "        \n",
    "        # Save raw data\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        save_raw_data(coingecko_data, f'solana_coingecko_enhanced_{timestamp}.joblib', \n",
    "                     'Enhanced CoinGecko data for Solana DeFi protocols')\n",
    "        \n",
    "        # Display sample\n",
    "        print(f\"\\nüìã Sample of collected data:\")\n",
    "        print(f\"{'Protocol':<25} {'Symbol':<8} {'Price':<12} {'Market Cap':<15} {'TVL':<15}\")\n",
    "        print(\"=\" * 75)\n",
    "        sorted_data = sorted(coingecko_data.items(), key=lambda x: x[1].get('market_cap_usd', 0), reverse=True)\n",
    "        for protocol_key, data in sorted_data[:15]:\n",
    "            protocol_name = data.get('protocol_name', protocol_key)[:24]\n",
    "            symbol = data.get('symbol', 'N/A')[:7]\n",
    "            price = f\"${data.get('current_price_usd', 0):.4f}\"\n",
    "            mcap = format_currency(data.get('market_cap_usd', 0))\n",
    "            tvl = format_currency(data.get('tvl', 0))\n",
    "            print(f\"{protocol_name:<25} {symbol:<8} {price:<12} {mcap:<15} {tvl:<15}\")\n",
    "        \n",
    "        # Summary stats\n",
    "        total_market_cap = sum(data.get('market_cap_usd', 0) for data in coingecko_data.values())\n",
    "        total_tvl = sum(data.get('tvl', 0) for data in coingecko_data.values())\n",
    "        positive_24h = sum(1 for data in coingecko_data.values() if data.get('price_change_24h_percent', 0) > 0)\n",
    "        \n",
    "        print(f\"\\nüìä Portfolio Summary:\")\n",
    "        print(f\"  ‚Ä¢ Total Market Cap: {format_currency(total_market_cap)}\")\n",
    "        print(f\"  ‚Ä¢ Total TVL: {format_currency(total_tvl)}\")\n",
    "        print(f\"  ‚Ä¢ Tokens with positive 24h change: {positive_24h}/{len(coingecko_data)}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Required data (tvl_df or jupiter_df) not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87d8a0",
   "metadata": {},
   "source": [
    "#### Step 5: Collect Helius Token Holder Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca8fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Helius Token Holder Data for Solana DeFi Protocols...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching token holders: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [03:47<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved cache: Token holder collection logs ‚Üí ..\\data\\temp\\token_holder_logs_20250905_121236.joblib\n",
      "\n",
      "‚úÖ Fetched data for 80 tokens. Records: 760\n",
      "üíæ Saved raw: Solana token holders DataFrame ‚Üí ..\\data\\api_responses\\solana_token_holders_20250905_121236.joblib\n",
      "Data saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Helius Token Holder Data for Solana DeFi Protocols...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "helius_url = f\"https://mainnet.helius-rpc.com/?api-key={API_KEYS['helius']}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def get_solana_token_holders(jupiter_df, coingecko_data, tvl_df):\n",
    "    # Basic input validation\n",
    "    if not (coingecko_data and isinstance(coingecko_data, dict)):\n",
    "        print(\"‚ùå No CoinGecko data available.\")\n",
    "        return pd.DataFrame()\n",
    "    if jupiter_df.empty or 'address' not in jupiter_df.columns:\n",
    "        print(\"‚ùå Jupiter token data missing or incomplete.\")\n",
    "        return pd.DataFrame()\n",
    "    if tvl_df.empty or 'symbol' not in tvl_df.columns:\n",
    "        print(\"‚ùå TVL data missing or incomplete.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Map protocol names to token addresses\n",
    "    token_map, unmatched = {}, []\n",
    "    for key, data in coingecko_data.items():\n",
    "        symbol = data.get('symbol', '').lower().strip()\n",
    "        protocol = data.get('protocol_name', key)\n",
    "        match = jupiter_df[jupiter_df['symbol'].str.lower() == symbol]\n",
    "        if not match.empty:\n",
    "            token_map[protocol] = match.iloc[0]['address']\n",
    "        else:\n",
    "            unmatched.append((protocol, symbol, data.get('coingecko_id', '')))\n",
    "    if unmatched:\n",
    "        print(f\"‚ö†Ô∏è {len(unmatched)} tokens not found in Jupiter list: {', '.join([f'{n} ({s})' for n, s, _ in unmatched[:5]])}\")\n",
    "        save_cache(unmatched, f'unmatched_tokens_{datetime.now():%Y%m%d_%H%M%S}.joblib', \"Unmatched tokens log\")\n",
    "\n",
    "    # Collect holders\n",
    "    holders, logs = [], []\n",
    "    for name, address in tqdm(token_map.items(), desc=\"Fetching token holders\"):\n",
    "        try:\n",
    "            payload = {\n",
    "                \"jsonrpc\": \"2.0\", \n",
    "                \"id\": \"1\", \n",
    "                \"method\": \"getTokenLargestAccounts\", \n",
    "                \"params\": [address]\n",
    "                }\n",
    "            resp = requests.post(helius_url, json=payload, headers=headers).json()\n",
    "            accounts = resp.get('result', {}).get('value', [])[:10]\n",
    "            if not accounts:\n",
    "                logs.append(f\"‚ö†Ô∏è No accounts found for {name}\")\n",
    "                continue\n",
    "            # Symbol fallback\n",
    "            symbol = coingecko_data.get(name.lower().replace(' ', '_'), {}).get('symbol', '')\n",
    "            if not symbol:\n",
    "                match = tvl_df[tvl_df['name'].str.lower() == name.lower()]\n",
    "                symbol = match.iloc[0]['symbol'] if not match.empty else name\n",
    "            # Add holder info\n",
    "            for rank, acc in enumerate(accounts, 1):\n",
    "                holders.append({\n",
    "                    'token_name': name, 'token_symbol': symbol, 'token_address': address,\n",
    "                    'rank': rank, 'account_address': acc['address'],\n",
    "                    'ui_amount': acc.get('uiAmount', 0), 'raw_amount': acc.get('amount', '0'),\n",
    "                    'decimals': acc.get('decimals', 0), 'timestamp': datetime.now()\n",
    "                })\n",
    "            logs.append(f\"‚úÖ {name}: {len(accounts)} accounts, top holder: {accounts[0].get('uiAmount', 0):,.0f} tokens\")\n",
    "            time.sleep(1.0)\n",
    "        except Exception as e:\n",
    "            logs.append(f\"‚ùå Error processing {name}: {e}\")\n",
    "\n",
    "    save_cache(logs, f'token_holder_logs_{datetime.now():%Y%m%d_%H%M%S}.joblib', \"Token holder collection logs\")\n",
    "    df = pd.DataFrame(holders)\n",
    "    # Add percentage column\n",
    "    if not df.empty:\n",
    "        df['percentage_of_top10'] = df.groupby('token_name')['ui_amount'].transform(lambda x: x / x.sum() * 100 if x.sum() > 0 else 0)\n",
    "    print(f\"\\n‚úÖ Fetched data for {len(token_map)} tokens. Records: {len(df)}\")\n",
    "    save_raw_data(df, f'solana_token_holders_{datetime.now():%Y%m%d_%H%M%S}.joblib', 'Solana token holders DataFrame')\n",
    "    return df\n",
    "\n",
    "# Run collection\n",
    "\n",
    "holders_data = get_solana_token_holders(jupiter_df, coingecko_data, tvl_df)\n",
    "print(\"Data saved to joblib file for further analysis\" if not holders_data.empty else \"\\n‚ùå Failed to collect token holders data\")\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51e96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
