{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc1a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Solana DeFi Tracker - Data Collection\n",
      "Cache directory: ..\\data\n",
      "Collection timestamp: 2025-09-05 14:00:51\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from Levenshtein import ratio\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add parent directory to sys.path for config imports\n",
    "parent_dir = str(Path().resolve().parent)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "from config.settings import API_KEYS, API_ENDPOINTS\n",
    "\n",
    "print(\"üìä Solana DeFi Tracker - Data Collection\")\n",
    "print(f\"Cache directory: {os.path.normpath('../data')}\")\n",
    "print(f\"Collection timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271dab4",
   "metadata": {},
   "source": [
    "#### Verify Cache Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e499b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cache directory exists: ../data/api_responses\n",
      "‚úÖ Cache directory exists: ../data/processed\n",
      "‚úÖ Cache directory exists: ../data/temp\n"
     ]
    }
   ],
   "source": [
    "# Verify cache directories exist, create if missing\n",
    "cache_dirs = ['../data/api_responses', '../data/processed', '../data/temp']\n",
    "for cache_dir in cache_dirs:\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        print(f\"‚úÖ Created cache directory: {cache_dir}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Cache directory exists: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111488c",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8701ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(url, headers=None, params=None, max_retries=3, is_post=False):\n",
    "    \"\"\"Make API request with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if is_post:\n",
    "                response = requests.post(url, headers=headers, json=params, timeout=30)\n",
    "            else:\n",
    "                response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "def save_raw_data(data, filename, description=\"\"):\n",
    "    \"\"\"Save raw API response to api_responses directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/api_responses/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved raw: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_processed_data(data, filename, description=\"\"):\n",
    "    \"\"\"Save processed data to processed directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/processed/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved processed: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_cache(data, filename, description=\"\"):\n",
    "    \"\"\"Save cache data to temp directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/temp/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved cache: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def load_cache(filename):\n",
    "    \"\"\"Load cache data from temp directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/temp/{filename}\")\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            return load(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to load cache {filename}: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def format_currency(amount):\n",
    "    \"\"\"Format currency amount with appropriate units (K, M, B)\"\"\"\n",
    "    if amount is None or amount == 0:\n",
    "        return \"$0\"\n",
    "    \n",
    "    if amount >= 1_000_000_000:\n",
    "        return f\"${amount/1_000_000_000:.2f}B\"\n",
    "    elif amount >= 1_000_000:\n",
    "        return f\"${amount/1_000_000:.2f}M\"\n",
    "    elif amount >= 1_000:\n",
    "        return f\"${amount/1_000:.2f}K\"\n",
    "    else:\n",
    "        return f\"${amount:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d873c0",
   "metadata": {},
   "source": [
    "#### Step 1: Collect DefiLlama Protocol Data (TVL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5415fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol TVL Data...\n",
      "‚úÖ DefiLlama API working! Found 6366 total protocols\n",
      "‚ö†Ô∏è Excluded 42 CEX-related protocols: Binance CEX, OKX, Bitfinex, Bybit, Gate\n",
      "üíæ Saved cache: Excluded CEX protocols log ‚Üí ..\\data\\temp\\excluded_protocols_20250905_140054.joblib\n",
      "üåü Found 252 Solana DeFi protocols:\n",
      "üìä Total Solana DeFi TVL: $77,749,203,760\n",
      "üìà Active protocols (TVL > 0): 220/252\n",
      "\n",
      "Rank  Protocol                  TVL             Category             1d Change \n",
      "=====================================================================================\n",
      "1     Lido                      $38.36B         Liquid Staking       -0.2%     \n",
      "2     Jito Liquid Staking       $3.05B          Liquid Staking       -1.5%     \n",
      "3     Portal                    $2.77B          Bridge               +1.4%     \n",
      "4     Kamino Lend               $2.61B          Lending              +0.3%     \n",
      "5     Sanctum Validator LSTs    $2.43B          Liquid Staking       +1.1%     \n",
      "6     Jupiter Perpetual Exchan  $2.41B          Derivatives          +0.7%     \n",
      "7     Raydium AMM               $2.32B          Dexs                 -0.4%     \n",
      "8     BlackRock BUIDL           $2.26B          RWA                  +0.0%     \n",
      "9     Maple                     $2.18B          Lending              +4.4%     \n",
      "10    Renzo                     $1.48B          Liquid Restaking     +1.4%     \n",
      "11    Ondo Yield Assets         $1.40B          RWA                  -0.2%     \n",
      "12    Gauntlet                  $1.39B          Risk Curators        +0.3%     \n",
      "13    Jupiter Staked SOL        $1.20B          Liquid Staking       -0.8%     \n",
      "14    Marinade Native           $1.03B          Staking Pool         +0.8%     \n",
      "15    Marinade Liquid Staking   $955.86M        Liquid Staking       -0.9%     \n",
      "16    Unit                      $908.16M        Bridge               +1.1%     \n",
      "17    Drift Trade               $906.55M        Derivatives          +1.9%     \n",
      "18    Meteora DLMM              $659.84M        Dexs                 -0.2%     \n",
      "19    Jupiter Lend              $570.14M        Lending              +5.9%     \n",
      "20    GMX V2 Perps              $548.22M        Derivatives          -0.5%     \n",
      "\n",
      "üìã Category Breakdown:\n",
      "Category                  Count    Total TVL      \n",
      "--------------------------------------------------\n",
      "Liquid Staking            27.0     $47.96B        \n",
      "Lending                   22.0     $5.84B         \n",
      "Dexs                      49.0     $4.72B         \n",
      "RWA                       12.0     $4.62B         \n",
      "Derivatives               18.0     $4.03B         \n",
      "Bridge                    11.0     $3.79B         \n",
      "Liquid Restaking          6.0      $1.64B         \n",
      "Risk Curators             1.0      $1.39B         \n",
      "Staking Pool              4.0      $1.21B         \n",
      "Basis Trading             6.0      $1.02B         \n",
      "üíæ Saved raw: Solana DeFi protocols TVL data ‚Üí ..\\data\\api_responses\\solana_defi_tvl_20250905_140055.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_defi_tvl_20250905_140055.joblib\n",
      "\n",
      "‚úÖ Successfully collected TVL data for 252 Solana DeFi protocols\n",
      "üìÅ DataFrame saved to joblib file for further analysis\n",
      "üìä Dataset includes 252 protocols worth $77,749,203,760 in total TVL\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol TVL Data...\")\n",
    "\n",
    "def get_all_solana_tvl_data():\n",
    "    \"\"\"\n",
    "    Collect TVL data for Solana DeFi protocols from DefiLlama, excluding CEX and CEX-related protocols.\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    # DefiLlama API endpoint for all protocols\n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    protocols_url = f\"{base_url}/protocols\"\n",
    "    \n",
    "    # Make the API request\n",
    "    all_protocols = make_request(protocols_url)\n",
    "    \n",
    "    if not all_protocols:\n",
    "        print(\"‚ùå DefiLlama API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ DefiLlama API working! Found {len(all_protocols)} total protocols\")\n",
    "    \n",
    "    # Comprehensive list of CEX names to exclude\n",
    "    cex_list = [\n",
    "        'binance', 'bybit', 'coinbase', 'kraken', 'kucoin', 'okx',\n",
    "        'crypto.com', 'crypto', 'bitfinex', 'huobi', 'htx', 'gate', 'gate.io',\n",
    "        'mexc', 'bitget', 'gemini', 'bitstamp', 'bithumb', 'bitpanda',\n",
    "        'bitmex', 'coinex', 'upbit', 'revolut', 'coindcx', 'bitflyer',\n",
    "        'coincheck', 'bitbank', 'swissborg', 'deribit'\n",
    "    ]\n",
    "    \n",
    "    # Filter for Solana DeFi protocols (excluding CEX and CEX-related)\n",
    "    solana_protocols = []\n",
    "    excluded_protocols = []\n",
    "    \n",
    "    for protocol in all_protocols:\n",
    "        chains = protocol.get('chains', [])\n",
    "        category = protocol.get('category', '').lower()\n",
    "        name = protocol.get('name', '').lower()\n",
    "        \n",
    "        is_solana = (\n",
    "            'Solana' in chains or \n",
    "            'solana' in chains or\n",
    "            any('solana' in str(chain).lower() for chain in chains) or\n",
    "            protocol.get('chain') == 'Solana'\n",
    "        )\n",
    "        \n",
    "        # Exclude CEX and CEX-related protocols\n",
    "        is_cex_related = (\n",
    "            category == 'cex' or\n",
    "            any(cex in name for cex in cex_list)\n",
    "        )\n",
    "        \n",
    "        if is_solana and not is_cex_related:\n",
    "            tvl_value = protocol.get('tvl') or 0\n",
    "            \n",
    "            solana_protocols.append({\n",
    "                'name': protocol.get('name', 'Unknown'),\n",
    "                'slug': protocol.get('slug', ''),\n",
    "                'tvl': tvl_value,\n",
    "                'chains': chains,\n",
    "                'category': protocol.get('category', 'Unknown'),\n",
    "                'change_1h': protocol.get('change_1h'),\n",
    "                'change_1d': protocol.get('change_1d'),\n",
    "                'change_7d': protocol.get('change_7d'),\n",
    "                'mcap': protocol.get('mcap'),\n",
    "                'symbol': protocol.get('symbol', ''),\n",
    "                'url': protocol.get('url', ''),\n",
    "                'description': protocol.get('description', ''),\n",
    "                'gecko_id': protocol.get(\"coingeckoId\"),\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        elif is_solana and is_cex_related:\n",
    "            excluded_protocols.append((protocol.get('name'), category))\n",
    "    \n",
    "    if excluded_protocols:\n",
    "        print(f\"‚ö†Ô∏è Excluded {len(excluded_protocols)} CEX-related protocols: {', '.join([name for name, _ in excluded_protocols[:5]])}\")\n",
    "        # Save excluded protocols log to cache directory\n",
    "        save_cache(excluded_protocols, f'excluded_protocols_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib', \n",
    "                    \"Excluded CEX protocols log\")  \n",
    "    \n",
    "    if not solana_protocols:\n",
    "        print(\"‚ùå No Solana DeFi protocols found\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(solana_protocols)\n",
    "    \n",
    "    # Sort by TVL descending\n",
    "    df = df.sort_values(by=\"tvl\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üåü Found {len(df)} Solana DeFi protocols:\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_tvl = df['tvl'].sum()\n",
    "    active_protocols = (df['tvl'] > 0).sum()\n",
    "    \n",
    "    print(f\"üìä Total Solana DeFi TVL: ${total_tvl:,.0f}\")\n",
    "    print(f\"üìà Active protocols (TVL > 0): {active_protocols}/{len(df)}\")\n",
    "    \n",
    "    # Display top protocols\n",
    "    print(f\"\\n{'Rank':<5} {'Protocol':<25} {'TVL':<15} {'Category':<20} {'1d Change':<10}\")\n",
    "    print(\"=\" * 85)\n",
    "    \n",
    "    for i, row in df.head(20).iterrows():\n",
    "        tvl_formatted = format_currency(row['tvl'])\n",
    "        change_1d = row['change_1d']\n",
    "        change_str = f\"{change_1d:+.1f}%\" if change_1d is not None else \"N/A\"\n",
    "        \n",
    "        print(f\"{i+1:<5} {row['name'][:24]:<25} {tvl_formatted:<15} \"\n",
    "              f\"{row['category'][:19]:<20} {change_str:<10}\")\n",
    "    \n",
    "    # Show category breakdown\n",
    "    category_breakdown = (\n",
    "        df.groupby(\"category\")['tvl']\n",
    "        .agg(['count', 'sum'])\n",
    "        .rename(columns={'count': 'protocols', 'sum': 'total_tvl'})\n",
    "        .sort_values(by=\"total_tvl\", ascending=False)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã Category Breakdown:\")\n",
    "    print(f\"{'Category':<25} {'Count':<8} {'Total TVL':<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for category, row in category_breakdown.head(10).iterrows():\n",
    "        print(f\"{category[:24]:<25} {row['protocols']:<8} {format_currency(row['total_tvl']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_defi_tvl_{timestamp}.joblib'\n",
    "    save_raw_data(df, filename, 'Solana DeFi protocols TVL data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute the collection\n",
    "tvl_df = get_all_solana_tvl_data()\n",
    "\n",
    "if tvl_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected TVL data for {len(tvl_df)} Solana DeFi protocols\")\n",
    "    print(\"üìÅ DataFrame saved to joblib file for further analysis\")\n",
    "    print(f\"üìä Dataset includes {len(tvl_df)} protocols worth ${tvl_df['tvl'].sum():,.0f} in total TVL\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect TVL data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e972c",
   "metadata": {},
   "source": [
    "#### Step 2: Collect DefiLlama Revenue Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a864fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol Revenue Data...\n",
      "üìä Solana Protocol Revenue Tracker\n",
      "==================================================\n",
      "‚úÖ Collected Solana revenue data\n",
      "Total protocols found: 104\n",
      "üíµ Found revenue data for 91 active protocols:\n",
      "\n",
      "Protocol                  24h Revenue     7d Revenue      30d Revenue    \n",
      "===========================================================================\n",
      "pump.fun                  $1.62M          $10.26M         $45.90M        \n",
      "Axiom                     $1.56M          $10.65M         $53.68M        \n",
      "Jupiter Perpetual Exchan  $785.31K        $5.74M          $23.71M        \n",
      "PumpSwap                  $541.92K        $2.16M          $6.39M         \n",
      "Phantom Wallet            $500.40K        $3.48M          $16.79M        \n",
      "Photon                    $159.93K        $1.05M          $5.94M         \n",
      "Solana                    $146.25K        $1.06M          $4.56M         \n",
      "Meteora DAMM V2           $124.96K        $895.45K        $6.17M         \n",
      "Binance Staked SOL        $124.92K        $572.36K        $1.61M         \n",
      "Raydium AMM               $96.78K         $803.08K        $3.58M         \n",
      "üíæ Saved raw: Solana revenue data ‚Üí ..\\data\\api_responses\\solana_revenue_20250905_140056.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_revenue_20250905_140056.joblib\n",
      "\n",
      "‚úÖ Successfully collected revenue data for 104 protocols\n",
      "üìÅ DataFrame saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol Revenue Data...\")\n",
    "\n",
    "def get_solana_revenue_data():\n",
    "    \"\"\"Collect REVENUE data from DefiLlama\"\"\"\n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    revenue_url = f\"{base_url}/overview/fees/solana\"\n",
    "    \n",
    "    #\n",
    "    params = {\n",
    "        'dataType': 'dailyRevenue', \n",
    "        'excludeTotalDataChart': 'true',\n",
    "        'excludeTotalDataChartBreakdown': 'true'\n",
    "    }\n",
    "    \n",
    "    data = make_request(revenue_url, params=params)\n",
    "    \n",
    "    if not data:\n",
    "        print(\"‚ùå Solana Revenue API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Collected Solana revenue data\")\n",
    "    print(f\"Total protocols found: {len(data.get('protocols', []))}\")\n",
    "    \n",
    "    protocols = data.get('protocols', [])\n",
    "    if not protocols:\n",
    "        print(\"No protocol data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort protocols by total24h in descending order\n",
    "    sorted_protocols = sorted(protocols, \n",
    "                            key=lambda x: x.get('total24h', 0) or 0, \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Build DataFrame\n",
    "    revenue_list = []\n",
    "    for protocol in sorted_protocols:\n",
    "        revenue_list.append({\n",
    "            'protocol': protocol.get('name', 'Unknown'),\n",
    "            'revenue_24h': protocol.get('total24h', 0),  \n",
    "            'revenue_7d': protocol.get('total7d', 0),    \n",
    "            'revenue_30d': protocol.get('total30d', 0),  \n",
    "            'revenue_all_time': protocol.get('totalAllTime', 0),\n",
    "            'data_type': 'revenue',  \n",
    "            'chain': 'solana',\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(revenue_list)\n",
    "    \n",
    "    # Display summary\n",
    "    protocols_with_data = (df['revenue_24h'] > 0).sum()\n",
    "    print(f\"üíµ Found revenue data for {protocols_with_data} active protocols:\")\n",
    "    \n",
    "    # Show top 10\n",
    "    top_protocols = df.sort_values(by=\"revenue_24h\", ascending=False).head(10)\n",
    "    print(f\"\\n{'Protocol':<25} {'24h Revenue':<15} {'7d Revenue':<15} {'30d Revenue':<15}\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    for _, row in top_protocols.iterrows():\n",
    "        if row['revenue_24h'] > 0:\n",
    "            print(f\"{row['protocol'][:24]:<25} {format_currency(row['revenue_24h']):<15} \"\n",
    "                  f\"{format_currency(row['revenue_7d']):<15} {format_currency(row['revenue_30d']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_revenue_{timestamp}.joblib'\n",
    "    save_raw_data(df, filename, 'Solana revenue data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"üìä Solana Protocol Revenue Tracker\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "revenue_df = get_solana_revenue_data()\n",
    "\n",
    "if revenue_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected revenue data for {len(revenue_df)} protocols\")\n",
    "    print(\"üìÅ DataFrame saved to joblib file for further analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect revenue data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e459231",
   "metadata": {},
   "source": [
    "#### Step 3: Collect Solana Fees Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bd14fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol Fees Data...\n",
      "üìä Solana Protocol Fees Tracker\n",
      "==================================================\n",
      "‚úÖ Collected Solana fees data\n",
      "Total protocols found: 117\n",
      "üí∞ Found fee data for 104 active protocols:\n",
      "\n",
      "Protocol                  24h Fees        7d Fees         30d Fees       \n",
      "======================================================================\n",
      "Jupiter Perpetual Exchan  $3.14M          $22.95M         $94.84M        \n",
      "PumpSwap                  $2.99M          $12.54M         $37.80M        \n",
      "pump.fun                  $1.62M          $10.26M         $45.90M        \n",
      "Axiom                     $1.56M          $10.65M         $53.68M        \n",
      "Solana                    $1.24M          $9.06M          $42.67M        \n",
      "Jito Liquid Staking       $1.06M          $4.13M          $12.50M        \n",
      "Meteora DLMM              $988.57K        $7.56M          $53.84M        \n",
      "Sanctum Validator LSTs    $905.43K        $3.64M          $12.86M        \n",
      "Binance Staked SOL        $793.21K        $3.26M          $10.59M        \n",
      "Raydium AMM               $645.47K        $5.37M          $24.34M        \n",
      "üíæ Saved raw: Solana fees data ‚Üí ..\\data\\api_responses\\solana_fees_20250905_140058.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_fees_20250905_140058.joblib\n",
      "\n",
      "‚úÖ Successfully collected fees data for 117 protocols\n",
      "Data saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol Fees Data...\")\n",
    "\n",
    "def get_solana_fees_data():\n",
    "    \n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    fees_url = f\"{base_url}/overview/fees/solana\"\n",
    "    \n",
    "  \n",
    "    params = {\n",
    "        'dataType': 'dailyFees',  \n",
    "        'excludeTotalDataChart': 'true',\n",
    "        'excludeTotalDataChartBreakdown': 'true'\n",
    "    }\n",
    "    \n",
    "    data = make_request(fees_url, params=params)\n",
    "    \n",
    "    if not data:\n",
    "        print(\"‚ùå Solana Fees API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Collected Solana fees data\")\n",
    "    print(f\"Total protocols found: {len(data.get('protocols', []))}\")\n",
    "    \n",
    "    protocols = data.get('protocols', [])\n",
    "    \n",
    "    if not protocols:\n",
    "        print(\"No protocol data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort protocols by total24h in descending order\n",
    "    sorted_protocols = sorted(protocols, \n",
    "                            key=lambda x: x.get('total24h', 0) or 0, \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Build list for DataFrame\n",
    "    fees_list = []\n",
    "    for protocol in sorted_protocols:\n",
    "        fees_list.append({\n",
    "            'protocol': protocol.get('name', 'Unknown'),\n",
    "            'fees_24h': protocol.get('total24h', 0),     \n",
    "            'fees_7d': protocol.get('total7d', 0),       \n",
    "            'fees_30d': protocol.get('total30d', 0),     \n",
    "            'fees_all_time': protocol.get('totalAllTime', 0),\n",
    "            'data_type': 'fees',  # Add data type identifier\n",
    "            'chain': 'solana',\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df2 = pd.DataFrame(fees_list)\n",
    "    \n",
    "    # Display summary\n",
    "    protocols_with_data = (df2['fees_24h'] > 0).sum()\n",
    "    print(f\"üí∞ Found fee data for {protocols_with_data} active protocols:\")\n",
    "    \n",
    "    # Show top 10\n",
    "    top_protocols = df2.sort_values(by=\"fees_24h\", ascending=False).head(10)\n",
    "    print(f\"\\n{'Protocol':<25} {'24h Fees':<15} {'7d Fees':<15} {'30d Fees':<15}\")\n",
    "    print(\"=\" * 70)\n",
    "    for _, row in top_protocols.iterrows():\n",
    "        if row['fees_24h'] > 0:\n",
    "            print(f\"{row['protocol'][:24]:<25} {format_currency(row['fees_24h']):<15} \"\n",
    "                  f\"{format_currency(row['fees_7d']):<15} {format_currency(row['fees_30d']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_fees_{timestamp}.joblib'\n",
    "    save_raw_data(df2, filename, 'Solana fees data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df2\n",
    "\n",
    "\n",
    "print(\"üìä Solana Protocol Fees Tracker\")\n",
    "print(\"=\" * 50)\n",
    "    \n",
    "fees_df = get_solana_fees_data()\n",
    "    \n",
    "if fees_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected fees data for {len(fees_df)} protocols\")\n",
    "    print(\"Data saved to joblib file for further analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect fees data\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb8b34",
   "metadata": {},
   "source": [
    "#### Get all Solana tokens list via Jupiter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b403a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Jupiter token list\n",
    "url = \"https://token.jup.ag/all\"\n",
    "resp = requests.get(url)\n",
    "tokens = resp.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(tokens)\n",
    "\n",
    "# Select useful columns\n",
    "jupiter_df = df[[\"address\", \"symbol\", \"name\", \"decimals\", \"logoURI\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897b208",
   "metadata": {},
   "source": [
    "#### Step 4: Collect CoinGecko Price and Supply Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Enhanced CoinGecko Data for Protocols...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching protocols to CoinGecko: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [06:14<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è 120 protocols unmatched: gauntlet, meteora dlmm, bouncebit cedefi yield, the vault liquid staking, superstate ustb...\n",
      "‚úÖ Matched 132 protocols with CoinGecko data\n",
      "üíæ Saved raw: Enhanced CoinGecko protocol data ‚Üí ..\\data\\api_responses\\solana_coingecko_enhanced_20250905_140727.joblib\n",
      "Data saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Enhanced CoinGecko Data for Protocols...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def get_coingecko_protocol_data(tvl_df):\n",
    "    if tvl_df.empty:\n",
    "        print(\"‚ùå No TVL data available for CoinGecko mapping.\")\n",
    "        return {}\n",
    "    # Get all CoinGecko coins list\n",
    "    coins_list_url = f\"{API_ENDPOINTS['coingecko']['base_url']}/coins/list\"\n",
    "    coins_list = make_request(coins_list_url, headers={\"x-cg-pro-api-key\": API_KEYS['coingecko']})\n",
    "    if not coins_list:\n",
    "        print(\"‚ùå Failed to fetch CoinGecko coins list.\")\n",
    "        return {}\n",
    "    coins_df = pd.DataFrame(coins_list)\n",
    "    coins_df['name_lower'] = coins_df['name'].str.lower().str.strip()\n",
    "    coins_df['symbol_lower'] = coins_df['symbol'].str.lower().str.strip()\n",
    "    # Prepare TVL data for matching\n",
    "    tvl_df['name_lower'] = tvl_df['name'].str.lower().str.strip()\n",
    "    tvl_df['symbol_lower'] = tvl_df['symbol'].str.lower().str.strip()\n",
    "    matched, unmatched = {}, []\n",
    "    for _, row in tqdm(tvl_df.iterrows(), total=len(tvl_df), desc=\"Matching protocols to CoinGecko\"):\n",
    "        name_lower, symbol_lower = row['name_lower'], row['symbol_lower']\n",
    "        # Match by name or symbol\n",
    "        match = coins_df[\n",
    "            (coins_df['name_lower'] == name_lower) |\n",
    "            (coins_df['symbol_lower'] == symbol_lower)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            coin_id = match.iloc[0]['id']\n",
    "            # Fetch detailed coin data using /coins/{id} endpoint\n",
    "            coin_url = f\"{API_ENDPOINTS['coingecko']['base_url']}/coins/{coin_id}\"\n",
    "            headers = {\"x-cg-pro-api-key\": API_KEYS['coingecko']}\n",
    "            params = {'localization': 'false', 'market_data': 'true'}  # Ensure market data is included\n",
    "            coin_data = make_request(coin_url, headers=headers, params=params)\n",
    "            if coin_data and 'market_data' in coin_data:\n",
    "                matched[name_lower] = {\n",
    "                    'protocol_name': row['name'],\n",
    "                    'symbol': coin_data.get('symbol', '').upper(),\n",
    "                    'current_price_usd': coin_data.get('market_data', {}).get('current_price', {}).get('usd', 0),\n",
    "                    'market_cap_usd': coin_data.get('market_data', {}).get('market_cap', {}).get('usd', 0),\n",
    "                    'price_change_24h_percent': coin_data.get('market_data', {}).get('price_change_percentage_24h', 0),\n",
    "                    'tvl': row.get('tvl', 0),\n",
    "                    'category': row.get('category', 'Unknown'),\n",
    "                    'coingecko_id': coin_id,\n",
    "                    'circulating_supply': coin_data.get('market_data', {}).get('circulating_supply', 0),  \n",
    "                    'total_supply': coin_data.get('market_data', {}).get('total_supply', 0) \n",
    "                }\n",
    "            time.sleep(1.0)  # Respect rate limits (Pro tier allows 100 calls/min, but cautious delay)\n",
    "        else:\n",
    "            unmatched.append(name_lower)\n",
    "    if unmatched:\n",
    "        print(f\"‚ö†Ô∏è {len(unmatched)} protocols unmatched: {', '.join(unmatched[:5])}...\")\n",
    "    print(f\"‚úÖ Matched {len(matched)} protocols with CoinGecko data\")\n",
    "    save_raw_data(matched, f'solana_coingecko_enhanced_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib', 'Enhanced CoinGecko protocol data')\n",
    "    return matched\n",
    "\n",
    "# Run collection\n",
    "coingecko_data = get_coingecko_protocol_data(tvl_df)\n",
    "print(\"Data saved to joblib file for further analysis\" if coingecko_data else \"\\n‚ùå Failed to collect CoinGecko data\")\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87d8a0",
   "metadata": {},
   "source": [
    "#### Step 5: Collect Helius Token Holder Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca8fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Helius Token Holder Data for Solana DeFi Protocols...\n",
      "==================================================\n",
      "‚ö†Ô∏è 14 tokens not found in Jupiter list: Maple (mpl), Unit ($unit), OpenEden TBILL (tbill), Apollo Diversified Credit Securitize Fund (acred), VanEck Treasury Fund (vbill)\n",
      "üíæ Saved cache: Unmatched tokens log ‚Üí ..\\data\\temp\\unmatched_tokens_20250905_140750.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching token holders: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [06:05<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved cache: Token holder collection logs ‚Üí ..\\data\\temp\\token_holder_logs_20250905_141356.joblib\n",
      "\n",
      "‚úÖ Fetched data for 118 tokens. Records: 1038\n",
      "üíæ Saved raw: Solana token holders DataFrame ‚Üí ..\\data\\api_responses\\solana_token_holders_20250905_141356.joblib\n",
      "Data saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Helius Token Holder Data for Solana DeFi Protocols...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "helius_url = f\"https://mainnet.helius-rpc.com/?api-key={API_KEYS['helius']}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def get_solana_token_holders(jupiter_df, coingecko_data, tvl_df):\n",
    "    # Basic input validation\n",
    "    if not (coingecko_data and isinstance(coingecko_data, dict)):\n",
    "        print(\"‚ùå No CoinGecko data available.\")\n",
    "        return pd.DataFrame()\n",
    "    if jupiter_df.empty or 'address' not in jupiter_df.columns:\n",
    "        print(\"‚ùå Jupiter token data missing or incomplete.\")\n",
    "        return pd.DataFrame()\n",
    "    if tvl_df.empty or 'symbol' not in tvl_df.columns:\n",
    "        print(\"‚ùå TVL data missing or incomplete.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Map protocol names to token addresses\n",
    "    token_map, unmatched = {}, []\n",
    "    for key, data in coingecko_data.items():\n",
    "        symbol = data.get('symbol', '').lower().strip()\n",
    "        protocol = data.get('protocol_name', key)\n",
    "        match = jupiter_df[jupiter_df['symbol'].str.lower() == symbol]\n",
    "        if not match.empty:\n",
    "            token_map[protocol] = match.iloc[0]['address']\n",
    "        else:\n",
    "            unmatched.append((protocol, symbol, data.get('coingecko_id', '')))\n",
    "    if unmatched:\n",
    "        print(f\"‚ö†Ô∏è {len(unmatched)} tokens not found in Jupiter list: {', '.join([f'{n} ({s})' for n, s, _ in unmatched[:5]])}\")\n",
    "        save_cache(unmatched, f'unmatched_tokens_{datetime.now():%Y%m%d_%H%M%S}.joblib', \"Unmatched tokens log\")\n",
    "\n",
    "    # Collect holders\n",
    "    holders, logs = [], []\n",
    "    for name, address in tqdm(token_map.items(), desc=\"Fetching token holders\"):\n",
    "        try:\n",
    "            payload = {\n",
    "                \"jsonrpc\": \"2.0\", \n",
    "                \"id\": \"1\", \n",
    "                \"method\": \"getTokenLargestAccounts\", \n",
    "                \"params\": [address]\n",
    "                }\n",
    "            resp = requests.post(helius_url, json=payload, headers=headers).json()\n",
    "            accounts = resp.get('result', {}).get('value', [])[:10]\n",
    "            if not accounts:\n",
    "                logs.append(f\"‚ö†Ô∏è No accounts found for {name}\")\n",
    "                continue\n",
    "            # Symbol fallback\n",
    "            symbol = coingecko_data.get(name.lower().replace(' ', '_'), {}).get('symbol', '')\n",
    "            if not symbol:\n",
    "                match = tvl_df[tvl_df['name'].str.lower() == name.lower()]\n",
    "                symbol = match.iloc[0]['symbol'] if not match.empty else name\n",
    "            # Add holder info\n",
    "            for rank, acc in enumerate(accounts, 1):\n",
    "                holders.append({\n",
    "                    'token_name': name, 'token_symbol': symbol, 'token_address': address,\n",
    "                    'rank': rank, 'account_address': acc['address'],\n",
    "                    'ui_amount': acc.get('uiAmount', 0), 'raw_amount': acc.get('amount', '0'),\n",
    "                    'decimals': acc.get('decimals', 0), 'timestamp': datetime.now()\n",
    "                })\n",
    "            logs.append(f\"‚úÖ {name}: {len(accounts)} accounts, top holder: {accounts[0].get('uiAmount', 0):,.0f} tokens\")\n",
    "            time.sleep(1.0)\n",
    "        except Exception as e:\n",
    "            logs.append(f\"‚ùå Error processing {name}: {e}\")\n",
    "\n",
    "    save_cache(logs, f'token_holder_logs_{datetime.now():%Y%m%d_%H%M%S}.joblib', \"Token holder collection logs\")\n",
    "    df = pd.DataFrame(holders)\n",
    "    # Add percentage column\n",
    "    if not df.empty:\n",
    "        df['percentage_of_top10'] = df.groupby('token_name')['ui_amount'].transform(lambda x: x / x.sum() * 100 if x.sum() > 0 else 0)\n",
    "    print(f\"\\n‚úÖ Fetched data for {len(token_map)} tokens. Records: {len(df)}\")\n",
    "    save_raw_data(df, f'solana_token_holders_{datetime.now():%Y%m%d_%H%M%S}.joblib', 'Solana token holders DataFrame')\n",
    "    return df\n",
    "\n",
    "# Run collection\n",
    "\n",
    "holders_data = get_solana_token_holders(jupiter_df, coingecko_data, tvl_df)\n",
    "print(\"Data saved to joblib file for further analysis\" if not holders_data.empty else \"\\n‚ùå Failed to collect token holders data\")\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0c534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
