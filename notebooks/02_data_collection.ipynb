{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc1a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Solana DeFi Tracker - Data Collection\n",
      "Cache directory: ..\\data\n",
      "Collection timestamp: 2025-09-02 10:02:40\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from Levenshtein import ratio\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add parent directory to sys.path for config imports\n",
    "parent_dir = str(Path().resolve().parent)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "from config.settings import API_KEYS, API_ENDPOINTS\n",
    "\n",
    "print(\"üìä Solana DeFi Tracker - Data Collection\")\n",
    "print(f\"Cache directory: {os.path.normpath('../data')}\")\n",
    "print(f\"Collection timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271dab4",
   "metadata": {},
   "source": [
    "#### Verify Cache Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e499b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cache directory exists: ../data/api_responses\n",
      "‚úÖ Cache directory exists: ../data/processed\n",
      "‚úÖ Cache directory exists: ../data/temp\n"
     ]
    }
   ],
   "source": [
    "# Verify cache directories exist, create if missing\n",
    "cache_dirs = ['../data/api_responses', '../data/processed', '../data/temp']\n",
    "for cache_dir in cache_dirs:\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        print(f\"‚úÖ Created cache directory: {cache_dir}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Cache directory exists: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111488c",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8701ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(url, headers=None, params=None, max_retries=3, is_post=False):\n",
    "    \"\"\"Make API request with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if is_post:\n",
    "                response = requests.post(url, headers=headers, json=params, timeout=30)\n",
    "            else:\n",
    "                response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "def save_raw_data(data, filename, description=\"\"):\n",
    "    \"\"\"Save raw API response to api_responses directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/api_responses/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved raw: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_processed_data(data, filename, description=\"\"):\n",
    "    \"\"\"Save processed data to processed directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/processed/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved processed: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_cache(data, filename, description=\"\"):\n",
    "    \"\"\"Save cache data to temp directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/temp/{filename}\")\n",
    "    dump(data, filepath)\n",
    "    print(f\"üíæ Saved cache: {description} ‚Üí {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def load_cache(filename):\n",
    "    \"\"\"Load cache data from temp directory\"\"\"\n",
    "    filepath = os.path.normpath(f\"../data/temp/{filename}\")\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            return load(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to load cache {filename}: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def format_currency(amount):\n",
    "    \"\"\"Format currency amount with appropriate units (K, M, B)\"\"\"\n",
    "    if amount is None or amount == 0:\n",
    "        return \"$0\"\n",
    "    \n",
    "    if amount >= 1_000_000_000:\n",
    "        return f\"${amount/1_000_000_000:.2f}B\"\n",
    "    elif amount >= 1_000_000:\n",
    "        return f\"${amount/1_000_000:.2f}M\"\n",
    "    elif amount >= 1_000:\n",
    "        return f\"${amount/1_000:.2f}K\"\n",
    "    else:\n",
    "        return f\"${amount:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d873c0",
   "metadata": {},
   "source": [
    "#### Step 1: Collect DefiLlama Protocol Data (TVL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5415fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol TVL Data...\n",
      "‚úÖ DefiLlama API working! Found 6346 total protocols\n",
      "‚ö†Ô∏è Excluded 41 CEX-related protocols: Binance CEX, OKX, Bitfinex, Bybit, Gate\n",
      "üíæ Saved cache: Excluded CEX protocols log ‚Üí ..\\data\\temp\\excluded_protocols_20250902_100252.joblib\n",
      "üåü Found 250 Solana DeFi protocols:\n",
      "üìä Total Solana DeFi TVL: $47,226,721,821\n",
      "üìà Active protocols (TVL > 0): 219/250\n",
      "\n",
      "Rank  Protocol                  TVL             Category             1d Change \n",
      "=====================================================================================\n",
      "1     Lido                      $8.54B          Liquid Staking       -77.9%    \n",
      "2     Jito Liquid Staking       $3.02B          Liquid Staking       +1.8%     \n",
      "3     Portal                    $2.72B          Bridge               -1.3%     \n",
      "4     Kamino Lend               $2.66B          Lending              +2.6%     \n",
      "5     BlackRock BUIDL           $2.41B          RWA                  +0.0%     \n",
      "6     Sanctum Validator LSTs    $2.36B          Liquid Staking       +2.5%     \n",
      "7     Jupiter Perpetual Exchan  $2.31B          Derivatives          +1.9%     \n",
      "8     Raydium AMM               $2.31B          Dexs                 +3.5%     \n",
      "9     Maple                     $2.03B          Lending              -1.8%     \n",
      "10    Ondo Finance              $1.40B          RWA                  -0.2%     \n",
      "11    Renzo                     $1.39B          Liquid Restaking     -4.4%     \n",
      "12    Gauntlet                  $1.38B          Risk Curators        -0.1%     \n",
      "13    Jupiter Staked SOL        $1.19B          Liquid Staking       +2.5%     \n",
      "14    Marinade Native           $990.46M        Staking Pool         +2.7%     \n",
      "15    Marinade Liquid Staking   $942.78M        Liquid Staking       +1.5%     \n",
      "16    Drift Trade               $902.76M        Derivatives          -0.3%     \n",
      "17    Unit                      $885.39M        Bridge               -10.9%    \n",
      "18    Meteora DLMM              $663.58M        Dexs                 +0.3%     \n",
      "19    GMX V2 Perps              $544.46M        Derivatives          -2.4%     \n",
      "20    PancakeSwap AMM V3        $518.06M        Dexs                 -0.5%     \n",
      "\n",
      "üìã Category Breakdown:\n",
      "Category                  Count    Total TVL      \n",
      "--------------------------------------------------\n",
      "Liquid Staking            26.0     $17.94B        \n",
      "Lending                   21.0     $5.64B         \n",
      "RWA                       12.0     $4.75B         \n",
      "Dexs                      49.0     $4.65B         \n",
      "Derivatives               19.0     $3.96B         \n",
      "Bridge                    10.0     $3.68B         \n",
      "Liquid Restaking          6.0      $1.56B         \n",
      "Risk Curators             1.0      $1.38B         \n",
      "Staking Pool              4.0      $1.16B         \n",
      "Basis Trading             6.0      $986.40M       \n",
      "üíæ Saved raw: Solana DeFi protocols TVL data ‚Üí ..\\data\\api_responses\\solana_defi_tvl_20250902_100252.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_defi_tvl_20250902_100252.joblib\n",
      "\n",
      "‚úÖ Successfully collected TVL data for 250 Solana DeFi protocols\n",
      "üìÅ DataFrame saved to joblib file for further analysis\n",
      "üìä Dataset includes 250 protocols worth $47,226,721,821 in total TVL\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol TVL Data...\")\n",
    "\n",
    "def get_all_solana_tvl_data():\n",
    "    \"\"\"\n",
    "    Collect TVL data for Solana DeFi protocols from DefiLlama, excluding CEX and CEX-related protocols.\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    # DefiLlama API endpoint for all protocols\n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    protocols_url = f\"{base_url}/protocols\"\n",
    "    \n",
    "    # Make the API request\n",
    "    all_protocols = make_request(protocols_url)\n",
    "    \n",
    "    if not all_protocols:\n",
    "        print(\"‚ùå DefiLlama API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ DefiLlama API working! Found {len(all_protocols)} total protocols\")\n",
    "    \n",
    "    # Comprehensive list of CEX names to exclude\n",
    "    cex_list = [\n",
    "        'binance', 'bybit', 'coinbase', 'kraken', 'kucoin', 'okx',\n",
    "        'crypto.com', 'crypto', 'bitfinex', 'huobi', 'htx', 'gate', 'gate.io',\n",
    "        'mexc', 'bitget', 'gemini', 'bitstamp', 'bithumb', 'bitpanda',\n",
    "        'bitmex', 'coinex', 'upbit', 'revolut', 'coindcx', 'bitflyer',\n",
    "        'coincheck', 'bitbank', 'swissborg', 'deribit'\n",
    "    ]\n",
    "    \n",
    "    # Filter for Solana DeFi protocols (excluding CEX and CEX-related)\n",
    "    solana_protocols = []\n",
    "    excluded_protocols = []\n",
    "    \n",
    "    for protocol in all_protocols:\n",
    "        chains = protocol.get('chains', [])\n",
    "        category = protocol.get('category', '').lower()\n",
    "        name = protocol.get('name', '').lower()\n",
    "        \n",
    "        is_solana = (\n",
    "            'Solana' in chains or \n",
    "            'solana' in chains or\n",
    "            any('solana' in str(chain).lower() for chain in chains) or\n",
    "            protocol.get('chain') == 'Solana'\n",
    "        )\n",
    "        \n",
    "        # Exclude CEX and CEX-related protocols\n",
    "        is_cex_related = (\n",
    "            category == 'cex' or\n",
    "            any(cex in name for cex in cex_list)\n",
    "        )\n",
    "        \n",
    "        if is_solana and not is_cex_related:\n",
    "            tvl_value = protocol.get('tvl') or 0\n",
    "            \n",
    "            solana_protocols.append({\n",
    "                'name': protocol.get('name', 'Unknown'),\n",
    "                'slug': protocol.get('slug', ''),\n",
    "                'tvl': tvl_value,\n",
    "                'chains': chains,\n",
    "                'category': protocol.get('category', 'Unknown'),\n",
    "                'change_1h': protocol.get('change_1h'),\n",
    "                'change_1d': protocol.get('change_1d'),\n",
    "                'change_7d': protocol.get('change_7d'),\n",
    "                'mcap': protocol.get('mcap'),\n",
    "                'symbol': protocol.get('symbol', ''),\n",
    "                'url': protocol.get('url', ''),\n",
    "                'description': protocol.get('description', ''),\n",
    "                'gecko_id': protocol.get(\"coingeckoId\"),\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        elif is_solana and is_cex_related:\n",
    "            excluded_protocols.append((protocol.get('name'), category))\n",
    "    \n",
    "    if excluded_protocols:\n",
    "        print(f\"‚ö†Ô∏è Excluded {len(excluded_protocols)} CEX-related protocols: {', '.join([name for name, _ in excluded_protocols[:5]])}\")\n",
    "        # Save excluded protocols log to cache directory\n",
    "        save_cache(excluded_protocols, f'excluded_protocols_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib', \n",
    "                    \"Excluded CEX protocols log\")  \n",
    "    \n",
    "    if not solana_protocols:\n",
    "        print(\"‚ùå No Solana DeFi protocols found\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(solana_protocols)\n",
    "    \n",
    "    # Sort by TVL descending\n",
    "    df = df.sort_values(by=\"tvl\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üåü Found {len(df)} Solana DeFi protocols:\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_tvl = df['tvl'].sum()\n",
    "    active_protocols = (df['tvl'] > 0).sum()\n",
    "    \n",
    "    print(f\"üìä Total Solana DeFi TVL: ${total_tvl:,.0f}\")\n",
    "    print(f\"üìà Active protocols (TVL > 0): {active_protocols}/{len(df)}\")\n",
    "    \n",
    "    # Display top protocols\n",
    "    print(f\"\\n{'Rank':<5} {'Protocol':<25} {'TVL':<15} {'Category':<20} {'1d Change':<10}\")\n",
    "    print(\"=\" * 85)\n",
    "    \n",
    "    for i, row in df.head(20).iterrows():\n",
    "        tvl_formatted = format_currency(row['tvl'])\n",
    "        change_1d = row['change_1d']\n",
    "        change_str = f\"{change_1d:+.1f}%\" if change_1d is not None else \"N/A\"\n",
    "        \n",
    "        print(f\"{i+1:<5} {row['name'][:24]:<25} {tvl_formatted:<15} \"\n",
    "              f\"{row['category'][:19]:<20} {change_str:<10}\")\n",
    "    \n",
    "    # Show category breakdown\n",
    "    category_breakdown = (\n",
    "        df.groupby(\"category\")['tvl']\n",
    "        .agg(['count', 'sum'])\n",
    "        .rename(columns={'count': 'protocols', 'sum': 'total_tvl'})\n",
    "        .sort_values(by=\"total_tvl\", ascending=False)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã Category Breakdown:\")\n",
    "    print(f\"{'Category':<25} {'Count':<8} {'Total TVL':<15}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for category, row in category_breakdown.head(10).iterrows():\n",
    "        print(f\"{category[:24]:<25} {row['protocols']:<8} {format_currency(row['total_tvl']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_defi_tvl_{timestamp}.joblib'\n",
    "    save_raw_data(df, filename, 'Solana DeFi protocols TVL data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute the collection\n",
    "tvl_df = get_all_solana_tvl_data()\n",
    "\n",
    "if tvl_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected TVL data for {len(tvl_df)} Solana DeFi protocols\")\n",
    "    print(\"üìÅ DataFrame saved to joblib file for further analysis\")\n",
    "    print(f\"üìä Dataset includes {len(tvl_df)} protocols worth ${tvl_df['tvl'].sum():,.0f} in total TVL\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect TVL data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e972c",
   "metadata": {},
   "source": [
    "#### Step 2: Collect DefiLlama Revenue Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a864fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol Revenue Data...\n",
      "üìä Solana Protocol Revenue Tracker\n",
      "==================================================\n",
      "‚úÖ Collected Solana revenue data\n",
      "Total protocols found: 104\n",
      "üíµ Found revenue data for 92 active protocols:\n",
      "\n",
      "Protocol                  24h Revenue     7d Revenue      30d Revenue    \n",
      "===========================================================================\n",
      "Axiom                     $1.38M          $11.23M         $53.25M        \n",
      "pump.fun                  $1.32M          $11.11M         $42.15M        \n",
      "Jupiter Perpetual Exchan  $1.14M          $5.91M          $22.74M        \n",
      "Phantom Wallet            $528.13K        $3.68M          $16.79M        \n",
      "Solana                    $151.09K        $1.08M          $4.53M         \n",
      "Meteora DAMM V2           $145.03K        $916.57K        $6.28M         \n",
      "PumpSwap                  $144.45K        $1.20M          $5.01M         \n",
      "Raydium AMM               $130.89K        $711.40K        $3.77M         \n",
      "Photon                    $121.67K        $1.12M          $5.99M         \n",
      "GMGN                      $103.66K        $739.51K        $3.34M         \n",
      "üíæ Saved raw: Solana revenue data ‚Üí ..\\data\\api_responses\\solana_revenue_20250902_100258.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_revenue_20250902_100258.joblib\n",
      "\n",
      "‚úÖ Successfully collected revenue data for 104 protocols\n",
      "üìÅ DataFrame saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol Revenue Data...\")\n",
    "\n",
    "def get_solana_revenue_data():\n",
    "    \"\"\"Collect REVENUE data from DefiLlama\"\"\"\n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    revenue_url = f\"{base_url}/overview/fees/solana\"\n",
    "    \n",
    "    #\n",
    "    params = {\n",
    "        'dataType': 'dailyRevenue', \n",
    "        'excludeTotalDataChart': 'true',\n",
    "        'excludeTotalDataChartBreakdown': 'true'\n",
    "    }\n",
    "    \n",
    "    data = make_request(revenue_url, params=params)\n",
    "    \n",
    "    if not data:\n",
    "        print(\"‚ùå Solana Revenue API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Collected Solana revenue data\")\n",
    "    print(f\"Total protocols found: {len(data.get('protocols', []))}\")\n",
    "    \n",
    "    protocols = data.get('protocols', [])\n",
    "    if not protocols:\n",
    "        print(\"No protocol data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort protocols by total24h in descending order\n",
    "    sorted_protocols = sorted(protocols, \n",
    "                            key=lambda x: x.get('total24h', 0) or 0, \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Build DataFrame\n",
    "    revenue_list = []\n",
    "    for protocol in sorted_protocols:\n",
    "        revenue_list.append({\n",
    "            'protocol': protocol.get('name', 'Unknown'),\n",
    "            'revenue_24h': protocol.get('total24h', 0),  \n",
    "            'revenue_7d': protocol.get('total7d', 0),    \n",
    "            'revenue_30d': protocol.get('total30d', 0),  \n",
    "            'revenue_all_time': protocol.get('totalAllTime', 0),\n",
    "            'data_type': 'revenue',  \n",
    "            'chain': 'solana',\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(revenue_list)\n",
    "    \n",
    "    # Display summary\n",
    "    protocols_with_data = (df['revenue_24h'] > 0).sum()\n",
    "    print(f\"üíµ Found revenue data for {protocols_with_data} active protocols:\")\n",
    "    \n",
    "    # Show top 10\n",
    "    top_protocols = df.sort_values(by=\"revenue_24h\", ascending=False).head(10)\n",
    "    print(f\"\\n{'Protocol':<25} {'24h Revenue':<15} {'7d Revenue':<15} {'30d Revenue':<15}\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    for _, row in top_protocols.iterrows():\n",
    "        if row['revenue_24h'] > 0:\n",
    "            print(f\"{row['protocol'][:24]:<25} {format_currency(row['revenue_24h']):<15} \"\n",
    "                  f\"{format_currency(row['revenue_7d']):<15} {format_currency(row['revenue_30d']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_revenue_{timestamp}.joblib'\n",
    "    save_raw_data(df, filename, 'Solana revenue data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"üìä Solana Protocol Revenue Tracker\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "revenue_df = get_solana_revenue_data()\n",
    "\n",
    "if revenue_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected revenue data for {len(revenue_df)} protocols\")\n",
    "    print(\"üìÅ DataFrame saved to joblib file for further analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect revenue data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e459231",
   "metadata": {},
   "source": [
    "#### Step 3: Collect Solana Fees Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bd14fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Solana Protocol Fees Data...\n",
      "üìä Solana Protocol Fees Tracker\n",
      "==================================================\n",
      "‚úÖ Collected Solana fees data\n",
      "Total protocols found: 117\n",
      "üí∞ Found fee data for 97 active protocols:\n",
      "\n",
      "Protocol                  24h Fees        7d Fees         30d Fees       \n",
      "======================================================================\n",
      "Jupiter Perpetual Exchan  $4.55M          $23.65M         $90.97M        \n",
      "Axiom                     $1.38M          $11.23M         $53.25M        \n",
      "pump.fun                  $1.32M          $11.11M         $42.15M        \n",
      "Solana                    $1.28M          $9.60M          $41.93M        \n",
      "Meteora DLMM              $1.16M          $8.04M          $54.40M        \n",
      "Raydium AMM               $873.30K        $4.81M          $25.59M        \n",
      "PumpSwap                  $862.58K        $7.19M          $29.94M        \n",
      "Meteora DAMM V2           $725.13K        $4.59M          $31.42M        \n",
      "Jito MEV Tips             $698.36K        $6.16M          $34.00M        \n",
      "Phantom Wallet            $528.13K        $3.68M          $16.79M        \n",
      "üíæ Saved raw: Solana fees data ‚Üí ..\\data\\api_responses\\solana_fees_20250902_100331.joblib\n",
      "\n",
      "üíæ DataFrame saved to solana_fees_20250902_100331.joblib\n",
      "\n",
      "‚úÖ Successfully collected fees data for 117 protocols\n",
      "Data saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Solana Protocol Fees Data...\")\n",
    "\n",
    "def get_solana_fees_data():\n",
    "    \n",
    "    base_url = API_ENDPOINTS['defillama']['base_url']\n",
    "    fees_url = f\"{base_url}/overview/fees/solana\"\n",
    "    \n",
    "  \n",
    "    params = {\n",
    "        'dataType': 'dailyFees',  \n",
    "        'excludeTotalDataChart': 'true',\n",
    "        'excludeTotalDataChartBreakdown': 'true'\n",
    "    }\n",
    "    \n",
    "    data = make_request(fees_url, params=params)\n",
    "    \n",
    "    if not data:\n",
    "        print(\"‚ùå Solana Fees API failed\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Collected Solana fees data\")\n",
    "    print(f\"Total protocols found: {len(data.get('protocols', []))}\")\n",
    "    \n",
    "    protocols = data.get('protocols', [])\n",
    "    \n",
    "    if not protocols:\n",
    "        print(\"No protocol data found.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort protocols by total24h in descending order\n",
    "    sorted_protocols = sorted(protocols, \n",
    "                            key=lambda x: x.get('total24h', 0) or 0, \n",
    "                            reverse=True)\n",
    "    \n",
    "    # Build list for DataFrame\n",
    "    fees_list = []\n",
    "    for protocol in sorted_protocols:\n",
    "        fees_list.append({\n",
    "            'protocol': protocol.get('name', 'Unknown'),\n",
    "            'fees_24h': protocol.get('total24h', 0),     \n",
    "            'fees_7d': protocol.get('total7d', 0),       \n",
    "            'fees_30d': protocol.get('total30d', 0),     \n",
    "            'fees_all_time': protocol.get('totalAllTime', 0),\n",
    "            'data_type': 'fees',  # Add data type identifier\n",
    "            'chain': 'solana',\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df2 = pd.DataFrame(fees_list)\n",
    "    \n",
    "    # Display summary\n",
    "    protocols_with_data = (df2['fees_24h'] > 0).sum()\n",
    "    print(f\"üí∞ Found fee data for {protocols_with_data} active protocols:\")\n",
    "    \n",
    "    # Show top 10\n",
    "    top_protocols = df2.sort_values(by=\"fees_24h\", ascending=False).head(10)\n",
    "    print(f\"\\n{'Protocol':<25} {'24h Fees':<15} {'7d Fees':<15} {'30d Fees':<15}\")\n",
    "    print(\"=\" * 70)\n",
    "    for _, row in top_protocols.iterrows():\n",
    "        if row['fees_24h'] > 0:\n",
    "            print(f\"{row['protocol'][:24]:<25} {format_currency(row['fees_24h']):<15} \"\n",
    "                  f\"{format_currency(row['fees_7d']):<15} {format_currency(row['fees_30d']):<15}\")\n",
    "    \n",
    "    # Save DataFrame to joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'solana_fees_{timestamp}.joblib'\n",
    "    save_raw_data(df2, filename, 'Solana fees data')\n",
    "    print(f\"\\nüíæ DataFrame saved to {filename}\")\n",
    "    \n",
    "    return df2\n",
    "\n",
    "\n",
    "print(\"üìä Solana Protocol Fees Tracker\")\n",
    "print(\"=\" * 50)\n",
    "    \n",
    "fees_df = get_solana_fees_data()\n",
    "    \n",
    "if fees_df is not None:\n",
    "    print(f\"\\n‚úÖ Successfully collected fees data for {len(fees_df)} protocols\")\n",
    "    print(\"Data saved to joblib file for further analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect fees data\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb8b34",
   "metadata": {},
   "source": [
    "#### Get all Solana tokens list via Jupiter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b403a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Jupiter token list\n",
    "url = \"https://token.jup.ag/all\"\n",
    "resp = requests.get(url)\n",
    "tokens = resp.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(tokens)\n",
    "\n",
    "# Select useful columns\n",
    "jupiter_df = df[[\"address\", \"symbol\", \"name\", \"decimals\", \"logoURI\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897b208",
   "metadata": {},
   "source": [
    "#### Step 4: Collect CoinGecko Price and Supply Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28e7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting CoinGecko Price and Supply Data for Solana DeFi Protocols...\n",
      "üìã Loaded 18518 coins from CoinGecko list\n",
      "üéØ Processing top 200 Solana protocols by TVL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching protocols: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [02:17<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Fetching market data in batch...\n",
      "üíæ Saved cache: CoinGecko coin details cache ‚Üí ..\\data\\temp\\coingecko_coin_cache.joblib\n",
      "üíæ Saved cache: CoinGecko search results cache ‚Üí ..\\data\\temp\\coingecko_search_cache.joblib\n",
      "\n",
      "‚úÖ Successfully collected CoinGecko data!\n",
      "üìä Processed: 200 protocols\n",
      "üéØ Successful matches: 80\n",
      "üìà Success rate: 40.0%\n",
      "üíæ Saved raw: Enhanced CoinGecko data for Solana DeFi protocols ‚Üí ..\\data\\api_responses\\solana_coingecko_enhanced_20250902_100638.joblib\n",
      "\n",
      "üìã Sample of collected data:\n",
      "Protocol                  Symbol   Price        Market Cap      TVL            \n",
      "===========================================================================\n",
      "BlackRock BUIDL           BUIDL    $1.0000      $2.40B          $2.41B         \n",
      "Penguin                   PENGU    $0.0294      $1.85B          $30.32K        \n",
      "Jupiter Lend              JUP      $0.4912      $1.53B          $490.09M       \n",
      "Saros DLMM                SAROS    $0.3650      $958.11M        $1.75M         \n",
      "Raydium AMM               RAY      $3.3900      $909.14M        $2.31B         \n",
      "PancakeSwap AMM V3        CAKE     $2.4300      $838.77M        $518.06M       \n",
      "Jito Restaking            JTO      $1.9000      $708.73M        $184.45M       \n",
      "Drift Staked SOL          DRIFT    $0.5701      $205.81M        $319.07M       \n",
      "Kamino Liquidity          KMNO     $0.0549      $147.12M        $292.07M       \n",
      "Orca DEX                  ORCA     $2.2500      $134.86M        $402.27M       \n",
      "Apollo Diversified Credi  ACRED    $1054.4700   $111.03M        $111.03M       \n",
      "Solayer USD               LAYER    $0.5140      $107.92M        $8.26M         \n",
      "VanEck Treasury Fund      VBILL    $1.0000      $75.41M         $75.41M        \n",
      "Marinade Select           MNDE     $0.1284      $72.01M         $173.91M       \n",
      "Bonk Staked SOL           BONKSOL  $229.9900    $44.65M         $44.81M        \n",
      "\n",
      "üìä Portfolio Summary:\n",
      "  ‚Ä¢ Total Market Cap: $10.55B\n",
      "  ‚Ä¢ Total TVL: $21.64B\n",
      "  ‚Ä¢ Tokens with positive 24h change: 37/80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüîç Collecting CoinGecko Price and Supply Data for Solana DeFi Protocols...\")\n",
    "\n",
    "def load_coingecko_list(cache_file='coingecko_coin_list.joblib'):\n",
    "    \"\"\"\n",
    "    Fetch or load cached CoinGecko coin list\n",
    "    \"\"\"\n",
    "    # Use the new cache loading method\n",
    "    cached_data = load_cache(cache_file)\n",
    "    if cached_data:\n",
    "        return cached_data\n",
    "    \n",
    "    try:\n",
    "        response = requests.get('https://api.coingecko.com/api/v3/coins/list')\n",
    "        if response.status_code == 200:\n",
    "            coin_list = response.json()\n",
    "            save_cache(coin_list, cache_file, \"CoinGecko coin list\")\n",
    "            return coin_list\n",
    "        else:\n",
    "            return []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def get_coingecko_id_from_name(protocol_name, protocol_symbol, coin_list, chains, coin_cache, search_cache):\n",
    "    \"\"\"\n",
    "    Try to find CoinGecko ID by first matching protocol symbol (exact match only, validated), then falling back to protocol name\n",
    "    \"\"\"\n",
    "    if not API_KEYS.get('coingecko'):\n",
    "        return None\n",
    "        \n",
    "    headers = {'X-Cg-Pro-Api-Key': API_KEYS['coingecko']}\n",
    "    search_url = f\"{API_ENDPOINTS['coingecko']['base_url']}/search\"\n",
    "    \n",
    "    # Clean protocol name for fallback matching\n",
    "    clean_name = protocol_name.lower().strip()\n",
    "    \n",
    "    # Step 1: Try exact symbol match (case-insensitive, validated)\n",
    "    if protocol_symbol and isinstance(protocol_symbol, str):\n",
    "        clean_symbol = protocol_symbol.lower().strip()\n",
    "        # Validate symbol: alphabetic, 2-10 characters\n",
    "        if re.match(r'^[a-zA-Z]{2,10}$', clean_symbol):\n",
    "            for coin in coin_list:\n",
    "                coin_symbol = coin.get('symbol', '').lower()\n",
    "                coin_id = coin.get('id')\n",
    "                \n",
    "                if clean_symbol == coin_symbol:\n",
    "                    # Check cache for coin details\n",
    "                    if coin_id in coin_cache:\n",
    "                        platforms = coin_cache[coin_id].get('platforms', {})\n",
    "                    else:\n",
    "                        coin_url = f\"{API_ENDPOINTS['coingecko']['base_url']}/coins/{coin_id}\"\n",
    "                        try:\n",
    "                            coin_data = make_request(coin_url, headers=headers, params={'localization': 'false'})\n",
    "                            if coin_data:\n",
    "                                coin_cache[coin_id] = coin_data\n",
    "                                platforms = coin_data.get('platforms', {})\n",
    "                            else:\n",
    "                                platforms = {}\n",
    "                        except Exception:\n",
    "                            platforms = {}\n",
    "                    \n",
    "                    # Strict Solana check: must have 'solana' in platforms\n",
    "                    if any('solana' in k.lower() for k in platforms.keys()):\n",
    "                        return coin_id\n",
    "    \n",
    "    # Step 2: Fallback to name-based matching\n",
    "    best_match = None\n",
    "    best_score = 0.9  # Stricter threshold\n",
    "    \n",
    "    for coin in coin_list:\n",
    "        coin_name = coin.get('name', '').lower()\n",
    "        coin_symbol = coin.get('symbol', '').lower()\n",
    "        coin_id = coin.get('id')\n",
    "        \n",
    "        # Skip known blockchain names\n",
    "        if coin_id in ['aptos', 'solana', 'ethereum', 'binancecoin']:\n",
    "            continue\n",
    "        \n",
    "        name_similarity = ratio(clean_name, coin_name) if len(clean_name) >= 4 and len(coin_name) >= 4 else 0\n",
    "        symbol_similarity = ratio(clean_name, coin_symbol) if len(clean_name) >= 3 and len(coin_symbol) >= 3 else 0\n",
    "        \n",
    "        if (clean_name == coin_name or\n",
    "            clean_name == coin_symbol or\n",
    "            (clean_name in coin_name and len(clean_name) >= 4) or\n",
    "            name_similarity > best_score or\n",
    "            symbol_similarity > best_score):\n",
    "            score = max(name_similarity, symbol_similarity, 1.0 if clean_name in coin_name else 0.0)\n",
    "            if score > best_score:\n",
    "                best_match = coin_id\n",
    "                best_score = score\n",
    "    \n",
    "    if best_match:\n",
    "        # Check cache for coin details\n",
    "        if best_match in coin_cache:\n",
    "            platforms = coin_cache[best_match].get('platforms', {})\n",
    "        else:\n",
    "            coin_url = f\"{API_ENDPOINTS['coingecko']['base_url']}/coins/{best_match}\"\n",
    "            try:\n",
    "                coin_data = make_request(coin_url, headers=headers, params={'localization': 'false'})\n",
    "                if coin_data:\n",
    "                    coin_cache[best_match] = coin_data\n",
    "                    platforms = coin_data.get('platforms', {})\n",
    "                else:\n",
    "                    platforms = {}\n",
    "            except Exception:\n",
    "                platforms = {}\n",
    "        \n",
    "        # Strict Solana check\n",
    "        if any('solana' in k.lower() for k in platforms.keys()):\n",
    "            return best_match\n",
    "    \n",
    "    # Step 3: Fallback to API search (cached)\n",
    "    if clean_name in search_cache:\n",
    "        return search_cache[clean_name]\n",
    "    \n",
    "    params = {'query': clean_name}\n",
    "    try:\n",
    "        search_data = make_request(search_url, headers=headers, params=params)\n",
    "        if search_data and 'coins' in search_data:\n",
    "            best_match = None\n",
    "            best_score = 0.9\n",
    "            \n",
    "            for coin in search_data['coins'][:3]:\n",
    "                coin_name = coin.get('name', '').lower()\n",
    "                coin_symbol = coin.get('symbol', '').lower()\n",
    "                coin_id = coin.get('id')\n",
    "                \n",
    "                # Skip known blockchain names\n",
    "                if coin_id in ['aptos', 'solana', 'ethereum', 'binancecoin']:\n",
    "                    continue\n",
    "                \n",
    "                name_similarity = ratio(clean_name, coin_name) if len(clean_name) >= 4 and len(coin_name) >= 4 else 0\n",
    "                symbol_similarity = ratio(clean_name, coin_symbol) if len(clean_name) >= 3 and len(coin_symbol) >= 3 else 0\n",
    "                \n",
    "                if (clean_name == coin_name or\n",
    "                    clean_name == coin_symbol or\n",
    "                    (clean_name in coin_name and len(clean_name) >= 4) or\n",
    "                    name_similarity > best_score or\n",
    "                    symbol_similarity > best_score):\n",
    "                    score = max(name_similarity, symbol_similarity, 1.0 if clean_name in coin_name else 0.0)\n",
    "                    if score > best_score:\n",
    "                        best_match = coin_id\n",
    "                        best_score = score\n",
    "            \n",
    "            if best_match:\n",
    "                # Check Solana for search fallback\n",
    "                if best_match in coin_cache:\n",
    "                    platforms = coin_cache[best_match].get('platforms', {})\n",
    "                else:\n",
    "                    coin_url = f\"{API_ENDPOINTS['coingecko']['base_url']}/coins/{best_match}\"\n",
    "                    try:\n",
    "                        coin_data = make_request(coin_url, headers=headers, params={'localization': 'false'})\n",
    "                        if coin_data:\n",
    "                            coin_cache[best_match] = coin_data\n",
    "                            platforms = coin_data.get('platforms', {})\n",
    "                        else:\n",
    "                            platforms = {}\n",
    "                    except Exception:\n",
    "                        platforms = {}\n",
    "                \n",
    "                if any('solana' in k.lower() for k in platforms.keys()):\n",
    "                    search_cache[clean_name] = best_match\n",
    "                    return best_match\n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    return None\n",
    "\n",
    "def batch_fetch_market_data(coingecko_ids, headers):\n",
    "    \"\"\"\n",
    "    Fetch market data for multiple CoinGecko IDs in a single request\n",
    "    \"\"\"\n",
    "    if not coingecko_ids:\n",
    "        return {}\n",
    "    \n",
    "    market_data = {}\n",
    "    batch_size = 100  # Safe for free-tier\n",
    "    for i in range(0, len(coingecko_ids), batch_size):\n",
    "        batch_ids = coingecko_ids[i:i + batch_size]\n",
    "        url = f\"{API_ENDPOINTS['coingecko']['base_url']}/coins/markets\"\n",
    "        params = {\n",
    "            'vs_currency': 'usd',\n",
    "            'ids': ','.join(batch_ids),\n",
    "            'order': 'market_cap_desc',\n",
    "            'per_page': batch_size,\n",
    "            'page': 1,\n",
    "            'sparkline': 'false',\n",
    "            'price_change_percentage': '24h,7d,30d'\n",
    "        }\n",
    "        try:\n",
    "            response = make_request(url, headers=headers, params=params)\n",
    "            if response:\n",
    "                for coin in response:\n",
    "                    market_data[coin['id']] = {\n",
    "                        'symbol': coin.get('symbol', '').upper(),\n",
    "                        'current_price_usd': coin.get('current_price', 0) or 0,\n",
    "                        'market_cap_usd': coin.get('market_cap', 0) or 0,\n",
    "                        'total_volume_24h_usd': coin.get('total_volume', 0) or 0,\n",
    "                        'price_change_24h_percent': coin.get('price_change_percentage_24h', 0) or 0,\n",
    "                        'price_change_7d_percent': coin.get('price_change_percentage_7d', 0) or 0,\n",
    "                        'price_change_30d_percent': coin.get('price_change_percentage_30d', 0) or 0,\n",
    "                        'circulating_supply': coin.get('circulating_supply', 0) or 0,\n",
    "                        'total_supply': coin.get('total_supply', 0) or 0,\n",
    "                        'max_supply': coin.get('max_supply'),\n",
    "                        'ath_usd': coin.get('ath', 0) or 0,\n",
    "                        'atl_usd': coin.get('atl', 0) or 0,\n",
    "                        'market_cap_rank': coin.get('market_cap_rank'),\n",
    "                        'fully_diluted_valuation': coin.get('fully_diluted_valuation', 0) or 0\n",
    "                    }\n",
    "            time.sleep(0.2)  # Adjust to 0.5s for free-tier\n",
    "        except Exception:\n",
    "            pass\n",
    "    return market_data\n",
    "\n",
    "def collect_coingecko_data_for_solana_protocols():\n",
    "    \"\"\"\n",
    "    Collect CoinGecko price data for Solana DeFi protocols found in TVL data\n",
    "    \"\"\"\n",
    "    if tvl_df.empty:\n",
    "        print(\"‚ùå No TVL data available. Please run the DefiLlama TVL collection first.\")\n",
    "        return {}\n",
    "    \n",
    "    if not API_KEYS.get('coingecko'):\n",
    "        print(\"‚ö†Ô∏è CoinGecko API key not found in .env\")\n",
    "        return {}\n",
    "    \n",
    "    headers = {'X-Cg-Pro-Api-Key': API_KEYS['coingecko']}\n",
    "    # Convert DataFrame rows to list of dictionaries\n",
    "    solana_protocols = tvl_df.to_dict('records')\n",
    "    \n",
    "    coingecko_data = {}\n",
    "    processed_count = 0\n",
    "    successful_count = 0\n",
    "    \n",
    "    # Load caches using new cache methods\n",
    "    coin_cache = load_cache('coingecko_coin_cache.joblib') or {}\n",
    "    search_cache = load_cache('coingecko_search_cache.joblib') or {}\n",
    "    \n",
    "    # Load the CoinGecko coin list once\n",
    "    coin_list = load_coingecko_list()\n",
    "    print(f\"üìã Loaded {len(coin_list)} coins from CoinGecko list\")\n",
    "    \n",
    "    # Focus on top protocols by TVL\n",
    "    top_protocols = sorted(solana_protocols, key=lambda x: x.get('tvl', 0), reverse=True)[:200]\n",
    "    \n",
    "    print(f\"üéØ Processing top {len(top_protocols)} Solana protocols by TVL...\")\n",
    "    \n",
    "    # Step 1: Collect CoinGecko IDs\n",
    "    coingecko_ids = []\n",
    "    protocol_map = {}\n",
    "    \n",
    "    for protocol in tqdm(top_protocols, desc=\"Matching protocols\"):\n",
    "        protocol_name = protocol.get('name', '').lower().strip()\n",
    "        protocol_symbol = protocol.get('symbol', '')\n",
    "        protocol_chains = protocol.get('chains', [])\n",
    "        protocol_slug = protocol.get('slug', '')\n",
    "        \n",
    "        if not protocol_name:\n",
    "            continue\n",
    "            \n",
    "        processed_count += 1\n",
    "        \n",
    "        # Find CoinGecko ID\n",
    "        coingecko_id = get_coingecko_id_from_name(protocol.get('name'), protocol_symbol, coin_list, protocol_chains, coin_cache, search_cache)\n",
    "        \n",
    "        if coingecko_id:\n",
    "            coingecko_ids.append(coingecko_id)\n",
    "            protocol_map[coingecko_id] = {\n",
    "                'protocol_name': protocol.get('name'),\n",
    "                'protocol_slug': protocol_slug,\n",
    "                'tvl': protocol.get('tvl', 0),\n",
    "                'category': protocol.get('category', '')\n",
    "            }\n",
    "    \n",
    "    # Step 2: Batch fetch market data\n",
    "    print(\"üì° Fetching market data in batch...\")\n",
    "    market_data = batch_fetch_market_data(list(set(coingecko_ids)), headers)\n",
    "    \n",
    "    # Step 3: Populate coingecko_data\n",
    "    for coingecko_id in market_data:\n",
    "        if coingecko_id in protocol_map:\n",
    "            protocol_info = protocol_map[coingecko_id]\n",
    "            key = protocol_info['protocol_slug'] or protocol_info['protocol_name'].lower().replace(' ', '_')\n",
    "            coingecko_data[key] = {\n",
    "                'protocol_name': protocol_info['protocol_name'],\n",
    "                'coingecko_id': coingecko_id,\n",
    "                'symbol': market_data[coingecko_id]['symbol'],\n",
    "                'current_price_usd': market_data[coingecko_id]['current_price_usd'],\n",
    "                'market_cap_usd': market_data[coingecko_id]['market_cap_usd'],\n",
    "                'total_volume_24h_usd': market_data[coingecko_id]['total_volume_24h_usd'],\n",
    "                'price_change_24h_percent': market_data[coingecko_id]['price_change_24h_percent'],\n",
    "                'price_change_7d_percent': market_data[coingecko_id]['price_change_7d_percent'],\n",
    "                'price_change_30d_percent': market_data[coingecko_id]['price_change_30d_percent'],\n",
    "                'circulating_supply': market_data[coingecko_id]['circulating_supply'],\n",
    "                'total_supply': market_data[coingecko_id]['total_supply'],\n",
    "                'max_supply': market_data[coingecko_id]['max_supply'],\n",
    "                'ath_usd': market_data[coingecko_id]['ath_usd'],\n",
    "                'atl_usd': market_data[coingecko_id]['atl_usd'],\n",
    "                'market_cap_rank': market_data[coingecko_id]['market_cap_rank'],\n",
    "                'fully_diluted_valuation': market_data[coingecko_id]['fully_diluted_valuation'],\n",
    "                'tvl': protocol_info['tvl'],\n",
    "                'category': protocol_info['category'],\n",
    "                'collection_timestamp': datetime.now()\n",
    "            }\n",
    "            successful_count += 1\n",
    "    \n",
    "    # Save caches using new cache method\n",
    "    save_cache(coin_cache, 'coingecko_coin_cache.joblib', \"CoinGecko coin details cache\")\n",
    "    save_cache(search_cache, 'coingecko_search_cache.joblib', \"CoinGecko search results cache\")\n",
    "    \n",
    "    return coingecko_data, processed_count, successful_count\n",
    "\n",
    "# Execute the collection\n",
    "if 'tvl_df' in locals() and not tvl_df.empty:\n",
    "    coingecko_data, processed_count, successful_count = collect_coingecko_data_for_solana_protocols()\n",
    "    \n",
    "    if coingecko_data:\n",
    "        print(f\"\\n‚úÖ Successfully collected CoinGecko data!\")\n",
    "        print(f\"üìä Processed: {processed_count} protocols\")\n",
    "        print(f\"üéØ Successful matches: {successful_count}\")\n",
    "        print(f\"üìà Success rate: {(successful_count/processed_count*100):.1f}%\")\n",
    "        \n",
    "        # Save raw data\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        save_raw_data(coingecko_data, f'solana_coingecko_enhanced_{timestamp}.joblib', \n",
    "                     'Enhanced CoinGecko data for Solana DeFi protocols')\n",
    "        \n",
    "        # Display sample of collected data\n",
    "        print(f\"\\nüìã Sample of collected data:\")\n",
    "        print(f\"{'Protocol':<25} {'Symbol':<8} {'Price':<12} {'Market Cap':<15} {'TVL':<15}\")\n",
    "        print(\"=\" * 75)\n",
    "        \n",
    "        # Sort by market cap for display\n",
    "        sorted_data = sorted(coingecko_data.items(), \n",
    "                           key=lambda x: x[1].get('market_cap_usd', 0), \n",
    "                           reverse=True)\n",
    "        \n",
    "        for protocol_key, data in sorted_data[:15]:  # Show top 15\n",
    "            protocol_name = data.get('protocol_name', protocol_key)[:24]\n",
    "            symbol = data.get('symbol', 'N/A')[:7]\n",
    "            price = f\"${data.get('current_price_usd', 0):.4f}\"\n",
    "            mcap = format_currency(data.get('market_cap_usd', 0))\n",
    "            tvl = format_currency(data.get('tvl', 0))\n",
    "            print(f\"{protocol_name:<25} {symbol:<8} {price:<12} {mcap:<15} {tvl:<15}\")\n",
    "            \n",
    "        # Create summary stats\n",
    "        total_market_cap = sum(data.get('market_cap_usd', 0) for data in coingecko_data.values())\n",
    "        total_tvl = sum(data.get('tvl', 0) for data in coingecko_data.values())\n",
    "        \n",
    "        print(f\"\\nüìä Portfolio Summary:\")\n",
    "        print(f\"  ‚Ä¢ Total Market Cap: {format_currency(total_market_cap)}\")\n",
    "        print(f\"  ‚Ä¢ Total TVL: {format_currency(total_tvl)}\")\n",
    "        print(f\"  ‚Ä¢ Tokens with positive 24h change: {sum(1 for data in coingecko_data.values() if data.get('price_change_24h_percent', 0) > 0)}/{len(coingecko_data)}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå TVL data not available. Please run the DefiLlama TVL collection cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87d8a0",
   "metadata": {},
   "source": [
    "#### Step 5: Collect Helius Token Holder Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca8fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Collecting Helius Token Holder Data for Solana DeFi Protocols...\n",
      "==================================================\n",
      "‚ö†Ô∏è 11 tokens not found in Jupiter list: Apollo Diversified Credit Securitize Fund (acred), VanEck Treasury Fund (vbill), DFDV Staked SOL (dfdvsol), Adrena Protocol (adx), FlashTrade (faf)\n",
      "üíæ Saved cache: Unmatched tokens log ‚Üí ..\\data\\temp\\unmatched_tokens_20250902_100657.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching token holders: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [02:42<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved cache: Token holder collection logs ‚Üí ..\\data\\temp\\token_holder_logs_20250902_100939.joblib\n",
      "\n",
      "‚úÖ Successfully fetched data for 68 tokens, 1 failures\n",
      "üìä DataFrame created with 626 records\n",
      "üíæ Saved raw: Solana token holders DataFrame ‚Üí ..\\data\\api_responses\\solana_token_holders_20250902_100940.joblib\n",
      "Data saved to joblib file for further analysis\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Collecting Helius Token Holder Data for Solana DeFi Protocols...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Helius API setup\n",
    "helius_url = f\"https://mainnet.helius-rpc.com/?api-key={API_KEYS['helius']}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def get_solana_token_holders(jupiter_df, coingecko_data, tvl_df):\n",
    "    \"\"\"\n",
    "    Collect top 10 largest accounts for each Solana protocol token matched in coingecko_data\n",
    "    Uses Jupiter token list for contract addresses and tvl_df for symbol fallback\n",
    "    Returns pandas DataFrame ready for charts and analysis\n",
    "    \"\"\"\n",
    "    if coingecko_data is None or not coingecko_data:\n",
    "        print(\"‚ùå No CoinGecko data available. Please run collect_coingecko_data.py first.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if jupiter_df.empty:\n",
    "        print(\"‚ùå No Jupiter token data available. Please run Jupiter token list collection first.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if 'address' not in jupiter_df.columns:\n",
    "        print(\"‚ùå Jupiter DataFrame missing 'address' column. Available columns:\", jupiter_df.columns.tolist())\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if tvl_df.empty or 'symbol' not in tvl_df.columns:\n",
    "        print(\"‚ùå tvl_df is empty or missing 'symbol' column. Available columns:\", tvl_df.columns.tolist())\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Create token mapping from coingecko_data and jupiter_df\n",
    "    token_map = {}\n",
    "    unmatched_tokens = []\n",
    "    \n",
    "    for protocol_key, data in coingecko_data.items():\n",
    "        symbol = data.get('symbol', '').lower().strip()\n",
    "        protocol_name = data.get('protocol_name', protocol_key)\n",
    "        coingecko_id = data.get('coingecko_id', '')\n",
    "        \n",
    "        # Find matching token in Jupiter list\n",
    "        jupiter_match = jupiter_df[jupiter_df['symbol'].str.lower() == symbol]\n",
    "        \n",
    "        if not jupiter_match.empty:\n",
    "            # Take first match (assume most relevant)\n",
    "            token_address = jupiter_match.iloc[0]['address']\n",
    "            token_map[protocol_name] = token_address\n",
    "        else:\n",
    "            unmatched_tokens.append((protocol_name, symbol, coingecko_id))\n",
    "    \n",
    "    if unmatched_tokens:\n",
    "        print(f\"‚ö†Ô∏è {len(unmatched_tokens)} tokens not found in Jupiter list: {', '.join([f'{name} ({symbol})' for name, symbol, _ in unmatched_tokens[:5]])}\")\n",
    "        # Save unmatched tokens log to cache directory\n",
    "        save_cache(unmatched_tokens, f'unmatched_tokens_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib', \n",
    "                  \"Unmatched tokens log\")\n",
    "    \n",
    "    all_holders_list = []\n",
    "    successful_requests = 0\n",
    "    failed_requests = 0\n",
    "    token_logs = []  # Store per-token logs for debugging\n",
    "    \n",
    "    for token_name, token_address in tqdm(token_map.items(), desc=\"Fetching token holders\"):\n",
    "        try:\n",
    "            # Prepare API payload\n",
    "            payload = {\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"id\": \"1\",\n",
    "                \"method\": \"getTokenLargestAccounts\",\n",
    "                \"params\": [token_address]\n",
    "            }\n",
    "            \n",
    "            # Make API request\n",
    "            response = requests.post(helius_url, json=payload, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            if 'result' not in result or 'value' not in result['result']:\n",
    "                token_logs.append(f\"‚ùå Error fetching data for {token_name}: {result.get('error', 'No data returned')}\")\n",
    "                failed_requests += 1\n",
    "                continue\n",
    "            \n",
    "            accounts = result['result']['value'][:10]  # Top 10 accounts\n",
    "            \n",
    "            if not accounts:\n",
    "                token_logs.append(f\"‚ö†Ô∏è No accounts found for {token_name}\")\n",
    "                failed_requests += 1\n",
    "                continue\n",
    "            \n",
    "            # Get token symbol: prioritize coingecko_data['symbol'], then tvl_df['symbol'], then token_name\n",
    "            coingecko_symbol = coingecko_data.get(token_name.lower().replace(' ', '_'), {}).get('symbol', '')\n",
    "            tvl_symbol = ''\n",
    "            if not coingecko_symbol:\n",
    "                # Look up symbol in tvl_df\n",
    "                tvl_match = tvl_df[tvl_df['name'].str.lower() == token_name.lower()]\n",
    "                if not tvl_match.empty:\n",
    "                    tvl_symbol = tvl_match.iloc[0]['symbol']\n",
    "            \n",
    "            token_symbol = coingecko_symbol or tvl_symbol or token_name\n",
    "            \n",
    "            # Store in list format for DataFrame\n",
    "            for rank, account in enumerate(accounts, 1):\n",
    "                all_holders_list.append({\n",
    "                    'token_name': token_name,\n",
    "                    'token_symbol': token_symbol,\n",
    "                    'token_address': token_address,\n",
    "                    'rank': rank,\n",
    "                    'account_address': account['address'],\n",
    "                    'ui_amount': account.get('uiAmount', 0),\n",
    "                    'raw_amount': account.get('amount', '0'),\n",
    "                    'decimals': account.get('decimals', 0),\n",
    "                    'timestamp': datetime.now()\n",
    "                })\n",
    "            \n",
    "            successful_requests += 1\n",
    "            top_holder_amount = accounts[0].get('uiAmount', 0) if accounts else 0\n",
    "            token_logs.append(f\"‚úÖ {token_name}: {len(accounts)} accounts, top holder: {top_holder_amount:,.0f} tokens\")\n",
    "            \n",
    "            # Rate limiting for Helius API\n",
    "            time.sleep(1.0)  # 1s delay to avoid rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            token_logs.append(f\"‚ùå Error processing {token_name}: {e}\")\n",
    "            failed_requests += 1\n",
    "            continue\n",
    "    \n",
    "    # Save token logs to cache directory\n",
    "    save_cache(token_logs, f'token_holder_logs_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.joblib', \n",
    "              \"Token holder collection logs\")\n",
    "    \n",
    "    # Create pandas DataFrame\n",
    "    df = pd.DataFrame(all_holders_list)\n",
    "    \n",
    "    if not df.empty:\n",
    "        # Calculate percentage of top 10 for each token\n",
    "        for token_name in df['token_name'].unique():\n",
    "            token_mask = df['token_name'] == token_name\n",
    "            token_total = df[token_mask]['ui_amount'].sum()\n",
    "            \n",
    "            if token_total > 0:\n",
    "                df.loc[token_mask, 'percentage_of_top10'] = (df.loc[token_mask, 'ui_amount'] / token_total * 100)\n",
    "            else:\n",
    "                df.loc[token_mask, 'percentage_of_top10'] = 0\n",
    "    \n",
    "    print(f\"\\n‚úÖ Successfully fetched data for {successful_requests} tokens, {failed_requests} failures\")\n",
    "    print(f\"üìä DataFrame created with {len(df)} records\")\n",
    "    \n",
    "    # Save as joblib\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    save_raw_data(df, f'solana_token_holders_{timestamp}.joblib', 'Solana token holders DataFrame')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Execute the collection\n",
    "holders_data = get_solana_token_holders(jupiter_df, coingecko_data, tvl_df)\n",
    "\n",
    "if not holders_data.empty:\n",
    "    print(\"Data saved to joblib file for further analysis\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to collect token holders data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51e96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
